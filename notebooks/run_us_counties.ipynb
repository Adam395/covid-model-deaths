{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from datetime import datetime, timedelta\n",
    "from multiprocessing import Pool\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 99\n",
    "pd.options.display.max_columns = 99\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from covid_model_deaths.data import get_input_data, plot_crude_rates, DeathModelData\n",
    "from covid_model_deaths.social_distancing_cov import SocialDistCov\n",
    "from covid_model_deaths.drawer import Drawer\n",
    "from covid_model_deaths.utilities import CompareModelDeaths, MOBILITY_SOURCES, KS, RATE_THRESHOLD, submit_curvefit, get_peak_date\n",
    "from covid_model_deaths.impute_death_threshold import impute_death_threshold\n",
    "from covid_model_deaths.moving_average import moving_average_predictions\n",
    "from covid_model_deaths.compare_moving_average import CompareAveragingModelDeaths\n",
    "\n",
    "from db_queries import get_location_metadata\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "## Set arguments and run settings ##\n",
    "# Set some arguments and settings #\n",
    "RUN_TYPE = 'dev'\n",
    "DATESTAMP_LABEL = '2020_04_22_Counties'\n",
    "DATA_VERSION = 'hospitals-and-counties/best' #'best'\n",
    "PEAK_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_14/final_peak_locs_04_14.csv'\n",
    "CASES_DEATHS_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_20/deaths_from_cases.csv'\n",
    "lsvid = 641\n",
    "\n",
    "CODE_DIR = os.path.abspath('../src/covid_model_deaths')\n",
    "OUTPUT_DIR = f'/ihme/covid-19/deaths/{RUN_TYPE}/{DATESTAMP_LABEL}'\n",
    "\n",
    "# Are we combining with previous predictions?\n",
    "combine_predictions = True\n",
    "raw_draw_path = f'{OUTPUT_DIR}/euro_data.csv'\n",
    "average_draw_path = f'{OUTPUT_DIR}/past_avg_euro_data.csv'\n",
    "yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_19_Europe/euro_data.csv'\n",
    "before_yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_17_Europe/euro_data.csv'\n",
    "\n",
    "# ensemble plot settings\n",
    "COLOR_DICT = {\n",
    "    'safegraph':'dodgerblue',\n",
    "    'google':'forestgreen',\n",
    "    'descartes':'firebrick'\n",
    "    #'equal':'gold',\n",
    "    #'ascmid':'firebrick',\n",
    "    #'ascmax':'darkviolet'\n",
    "}\n",
    "LINE_DICT = {\n",
    "    #'14':'-',\n",
    "    '21':'--'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE_DIR = os.path.abspath('../src/covid_model_deaths')\n",
    "# OUTPUT_DIR = f'/ihme/covid-19/deaths/{RUN_TYPE}/{DATESTAMP_LABEL}'\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "print(f'Writing to {OUTPUT_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# come up with more informative names...\n",
    "input_full_df = get_input_data('full_data', DATA_VERSION)\n",
    "input_death_df = get_input_data('deaths', DATA_VERSION)\n",
    "input_age_pop_df = get_input_data('age_pop', DATA_VERSION)\n",
    "input_age_death_df = get_input_data('age_death', DATA_VERSION)\n",
    "\n",
    "# manually adjust Iceland spike (0 deaths to 5 deaths to 0 deaths in March...)\n",
    "input_full_df.loc[(input_full_df['Country/Region'] == 'Iceland') & (input_full_df['Date'] == pd.Timestamp('2020-03-15')), ['Deaths', 'Death rate']] = 0\n",
    "input_death_df = input_death_df.loc[(input_death_df['Country/Region'] != 'Iceland') | (input_death_df['Date'] != pd.Timestamp('2020-03-15'))]\n",
    "input_death_df.loc[input_death_df['Country/Region'] == 'Iceland', 'Days'] = input_death_df.loc[\n",
    "    input_death_df['Country/Region'] == 'Iceland', 'Date'\n",
    "].apply(lambda x: (x - input_death_df.loc[input_death_df['Country/Region'] == 'Iceland', 'Date'].min()).days)\n",
    "\n",
    "# drop Georgia the country until we fix location_ids\n",
    "input_full_df = input_full_df[input_full_df['Country/Region'] != 'Georgia'].reset_index(drop=True)\n",
    "input_death_df = input_death_df[input_death_df['Country/Region'] != 'Georgia'].reset_index(drop=True)\n",
    "\n",
    "# Change location_id for Miami\n",
    "miami = input_full_df[input_full_df['location_id'] == 60408]\n",
    "miami['location_id'] = 957\n",
    "input_full_df = input_full_df.append(miami)\n",
    "input_full_df = input_full_df[input_full_df['location_id'] != 60408]\n",
    "\n",
    "# And in input_death_df\n",
    "miami = input_death_df[input_death_df['location_id'] == 60408]\n",
    "miami['location_id'] = 957\n",
    "input_death_df = input_death_df.append(miami)\n",
    "input_death_df = input_death_df[input_death_df['location_id'] != 60408]\n",
    "\n",
    "# # make a picture\n",
    "# plot_crude_rates(input_death_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix closure sheet (is occurring in social_distancing_cov.py)\n",
    "I feel like this should work but it doesn't. I believe this is because the values are converted to floats, which don't merge later. \n",
    "I am making the change directly in the closure_criteria_sheet.xlsx because I can't figure out how to fix it here.\n",
    "I am assuming that the counties have the same closures as the state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/ihme/covid-19/model-inputs/{data_version}/closure_criteria_sheet.xlsx\n",
    "df = pd.read_excel(f'/ihme/covid-19/model-inputs/hospitals-and-counties/best/closure_criteria_sheet.xlsx')\n",
    "\n",
    "ca_ids = [787,790,792,794,796,799,814]\n",
    "ca_names = ['Marin County','Contra Costa County','San Francisco County','Alameda County','San Mateo County','Santa Clara County','Los Angeles County']\n",
    "for location_id, location in zip(ca_ids, ca_names):\n",
    "    nrep = df[df['location_id'] == 527]\n",
    "    nrep['merge_name'] = location\n",
    "    nrep['location_id'] = location_id\n",
    "    df = df.append(nrep)\n",
    "ny_ids = [60410, 60411]\n",
    "ny_names = ['New York Metropolitan Area', 'Outside of New York City']\n",
    "for location_id, location in zip(ny_ids, ny_names):\n",
    "    nrep = df[df['location_id'] == 555]\n",
    "    nrep['merge_name'] = location\n",
    "    nrep['location_id'] = location_id\n",
    "    df = df.append(nrep)\n",
    "    \n",
    "nrep = df[df['location_id'] == 558]\n",
    "nrep['merge_name'] = 'UC Health'\n",
    "nrep['location_id'] = int(60416)\n",
    "df = df.append(nrep)    \n",
    "\n",
    "nrep = df[df['location_id'] == 532]\n",
    "nrep['merge_name'] = 'Miami'\n",
    "nrep['location_id'] = 957\n",
    "df = df.append(nrep)  \n",
    "\n",
    "# df['location_id'] = df['location_id'].astype(int)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some counties and states are missing age curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A fatal error: Florida and New York have no age-curve populations!\n",
    "# Also missing data for many new CA counties\n",
    "# Not sure of an efficient way to do this but here we go\n",
    "fill_pops = pd.read_csv('/ihme/covid-19/model-inputs/best/age_pop.csv')\n",
    "fl_pops = fill_pops[fill_pops['location_id'] == 532]\n",
    "ny_pops = fill_pops[fill_pops['location_id'] == 555]\n",
    "ca_pops = fill_pops[fill_pops['location_id'] == 527]\n",
    "st_pops = fill_pops[fill_pops['location_id'] == 558]\n",
    "input_age_pop_df = input_age_pop_df.append(fl_pops)\n",
    "input_age_pop_df = input_age_pop_df.append(ny_pops)\n",
    "input_age_pop_df = input_age_pop_df.append(ca_pops)\n",
    "input_age_pop_df = input_age_pop_df.append(st_pops)\n",
    "\n",
    "# Remove empty rows for \n",
    "\n",
    "# Now add counties sequentially\n",
    "county_ids = [787, 790, 792, 794, 796, 799]\n",
    "input_age_pop_df = input_age_pop_df[input_age_pop_df['location_id'] != 787]\n",
    "input_age_pop_df = input_age_pop_df[input_age_pop_df['location_id'] != 790]\n",
    "input_age_pop_df = input_age_pop_df[input_age_pop_df['location_id'] != 792]\n",
    "input_age_pop_df = input_age_pop_df[input_age_pop_df['location_id'] != 794]\n",
    "input_age_pop_df = input_age_pop_df[input_age_pop_df['location_id'] != 796]\n",
    "input_age_pop_df = input_age_pop_df[input_age_pop_df['location_id'] != 799]\n",
    "for ids in county_ids:\n",
    "    county_pops = ca_pops\n",
    "    county_pops['location_id'] = ids\n",
    "    input_age_pop_df = input_age_pop_df.append(county_pops)\n",
    "    \n",
    "# Change location_id for Miami\n",
    "miami = input_age_pop_df[input_age_pop_df['location_id'] == 60408]\n",
    "miami['location_id'] = 957\n",
    "input_age_pop_df = input_age_pop_df.append(miami)\n",
    " \n",
    "#input_age_pop_df.tail(75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## identify locations we are running\n",
    "#### location sets posted in slack channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get locaton_ids\n",
    "# Changed this so we can set at the top\n",
    "loc_df = get_location_metadata(location_set_id=112, location_set_version_id=lsvid)\n",
    "\n",
    "# Drop any locations in the US and keep only most detailed for modeling\n",
    "euro_df = loc_df.loc[\n",
    "    (loc_df['most_detailed']==1) & ~loc_df['path_to_top_parent'].str.startswith('102,'),\n",
    "    ['location_id', 'location_ascii_name', 'parent_id', 'level', 'most_detailed']\n",
    "]\n",
    "\n",
    "# format\n",
    "euro_df = euro_df.rename(index=str, columns={'location_ascii_name':'Location'})\n",
    "loc_df = loc_df[['location_id', 'location_ascii_name']]\n",
    "loc_df = loc_df.rename(index=str, columns={'location_id':'parent_id',\n",
    "                                           'location_ascii_name':'Country/Region'})\n",
    "euro_df = euro_df.merge(loc_df)\n",
    "\n",
    "# Dropping these locations due to an error in the hierarchy -- non-mutually exclusive (relevant for lsvid 637)\n",
    "euro_df = euro_df.loc[(euro_df.most_detailed == 1) &\n",
    "                      (~euro_df.location_id.isin([53451, 53452, 53474])),\n",
    "                      ['location_id', 'Location', 'Country/Region', 'level']]\n",
    "# Dropping counties without more than 1 day of data\n",
    "euro_df = euro_df.loc[(~euro_df.location_id.isin([780, 781, 787, 789, 790, 792, 794, 796, 799, 60414])),\n",
    "                      ['location_id', 'Location', 'Country/Region', 'level']]\n",
    "euro_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data for case-to-death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "location_ids = sorted(input_full_df.loc[(np.log(input_full_df['Death rate']) > RATE_THRESHOLD),\n",
    "                                  'location_id'].unique())\n",
    "\n",
    "start_time = datetime.now()\n",
    "def combine_cases_w_backcast_deaths(location_id, input_death_df, input_age_pop_df, input_age_death_df, rate_threshold):\n",
    "    mod_df = DeathModelData(input_death_df, input_age_pop_df, input_age_death_df, location_id, 'threshold', rate_threshold=RATE_THRESHOLD).df\n",
    "    mod_df = mod_df.loc[mod_df['location_id'] == location_id].reset_index(drop=True)\n",
    "    if len(mod_df) > 0:\n",
    "        date0 = mod_df['Date'].min()\n",
    "        day0 = mod_df.loc[~mod_df['Date'].isnull(), 'Days'].min()\n",
    "        mod_df.loc[mod_df['Days'] == 0, 'Date'] = date0 - timedelta(days=np.round(day0))\n",
    "        mod_df = mod_df.loc[~((mod_df['Deaths'].isnull()) & (mod_df['Date'] == date0))]\n",
    "        mod_df = mod_df.loc[~mod_df['Date'].isnull()]\n",
    "        mod_df.loc[mod_df['Death rate'].isnull(), 'Death rate'] = np.exp(mod_df['ln(age-standardized death rate)'])\n",
    "        mod_df.loc[mod_df['Deaths'].isnull(), 'Deaths'] = mod_df['Death rate'] * mod_df['population']\n",
    "        mod_df = mod_df.rename(index=str, columns={'Location':'Province/State'})\n",
    "    else:\n",
    "        mod_df = pd.DataFrame(\n",
    "            columns=['location_id', 'Province/State', 'Country/Region', 'Date', 'Deaths', 'Death rate', 'population']\n",
    "        )\n",
    "\n",
    "    return mod_df[['location_id', 'Province/State', 'Country/Region', 'Date', 'Deaths', 'Death rate', 'population']].reset_index(drop=True)\n",
    "\n",
    "_combiner = functools.partial(combine_cases_w_backcast_deaths,\n",
    "                              input_death_df=input_death_df,\n",
    "                              input_age_pop_df=input_age_pop_df,\n",
    "                              input_age_death_df=input_age_death_df,\n",
    "                              rate_threshold=RATE_THRESHOLD)\n",
    "pool = Pool(20)\n",
    "loc_dfs = pool.map(_combiner, location_ids)\n",
    "pool.close()\n",
    "pool.join()\n",
    "loc_df = pd.concat(loc_dfs)\n",
    "loc_df = input_full_df[['location_id', 'Province/State', 'Country/Region', 'Date', 'Confirmed', 'Confirmed case rate']].merge(\n",
    "    loc_df, how='outer'\n",
    ").reset_index(drop=True)\n",
    "loc_df.loc[loc_df['Province/State'].isnull(), 'Province/State'] = loc_df['Country/Region']\n",
    "loc_df['location_id'] = loc_df['location_id'].astype(int)\n",
    "loc_df.to_csv(f'{OUTPUT_DIR}/backcast_for_case_to_death.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = impute_death_threshold(loc_df,\n",
    "                                 location_list=euro_df['location_id'].unique().tolist(),\n",
    "                                 ln_death_rate_threshold=RATE_THRESHOLD)\n",
    "id_map_df = input_full_df[['location_id', 'Province/State', 'Country/Region']].drop_duplicates()\n",
    "id_map_df.loc[id_map_df['Province/State'].isnull(), 'Province/State'] = id_map_df['Country/Region']\n",
    "del id_map_df['Country/Region']\n",
    "id_map_df = id_map_df.rename(index=str, columns={'Province/State':'location'})\n",
    "date_df = id_map_df[['location_id', 'location']].merge(date_df)\n",
    "date_df.to_csv(f'{OUTPUT_DIR}/threshold_dates.csv', index=False)\n",
    "del loc_df\n",
    "del id_map_df\n",
    "end_time = datetime.now()\n",
    "print(end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store pops for Bobby\n",
    "pop_df = input_age_pop_df.merge(euro_df).reset_index(drop=True)\n",
    "pop_df[['location_id', 'Location', 'age_group', 'population']].to_csv(f'{OUTPUT_DIR}/pops.csv', index=False)\n",
    "print(f'{OUTPUT_DIR}/pops.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store model data and covariate data, submit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for getting dates\n",
    "def date_mean(dates):\n",
    "    dt_min = dates.min()\n",
    "    deltas = [x-dt_min for x in dates]\n",
    "\n",
    "    return dt_min + functools.reduce(operator.add, deltas) / len(deltas)\n",
    "\n",
    "# get mean data from dataset\n",
    "date_draws = [i for i in date_df.columns if i.startswith('death_date_draw_')]\n",
    "date_mean_df = date_df.copy()\n",
    "date_mean_df['threshold_date'] = date_mean_df.apply(\n",
    "    lambda x: datetime.strptime(date_mean(x[date_draws]).strftime('%Y-%m-%d'), '%Y-%m-%d'),\n",
    "    axis=1\n",
    ")\n",
    "date_mean_df = date_mean_df.rename(index=str, columns={'location':'Location'})\n",
    "country_label_df = input_full_df[['Province/State', 'Country/Region']].drop_duplicates().reset_index(drop=True)\n",
    "country_label_df.loc[country_label_df['Province/State'].isnull(), 'Province/State'] = country_label_df['Country/Region']\n",
    "country_label_df = country_label_df.rename(index=str, columns={'Province/State':'Location'})\n",
    "date_mean_df = date_mean_df.merge(country_label_df, how='outer')\n",
    "if date_mean_df['Country/Region'].isnull().any():\n",
    "    raise ValueError('Trouble attaching country names,')\n",
    "date_mean_df = date_mean_df[['location_id', 'Location', 'Country/Region', 'threshold_date']]\n",
    "\n",
    "# set up ensemble\n",
    "def get_out_dirs(model_labels):\n",
    "    model_out_dirs = []\n",
    "    for model_label in model_labels:\n",
    "        for k in KS:\n",
    "            # set up dirs\n",
    "            model_out_dir = f'{OUTPUT_DIR}/model_data_{model_label}_{k}'\n",
    "            if not os.path.exists(model_out_dir):\n",
    "                os.mkdir(model_out_dir)\n",
    "            model_out_dirs.append(model_out_dir)\n",
    "\n",
    "    return model_out_dirs\n",
    "def get_draw_list(n_scenarios):\n",
    "    n_draws_list = [int(1000 / n_scenarios)] * n_scenarios\n",
    "    n_draws_list[-1] = n_draws_list[-1] + 1000 - np.sum(n_draws_list)\n",
    "\n",
    "    return n_draws_list\n",
    "\n",
    "# prepare last day dataset\n",
    "last_day_df = input_full_df.copy()\n",
    "last_day_df['last_day'] = last_day_df.groupby('location_id', as_index=False)['Date'].transform(max)\n",
    "last_day_df = last_day_df.loc[last_day_df['Date'] == last_day_df['last_day']].reset_index(drop=True)\n",
    "last_day_df['location_id'] = last_day_df['location_id'].astype(int)\n",
    "last_day_df.loc[last_day_df['Death rate'] == 0, 'Death rate'] = 0.1 / last_day_df['population']\n",
    "last_day_df['ln(death rate)'] = np.log(last_day_df['Death rate'])\n",
    "last_day_df = last_day_df[['location_id', 'ln(death rate)', 'Date']].merge(date_mean_df)\n",
    "last_day_df['Days'] = (last_day_df['Date'] - last_day_df['threshold_date'])\n",
    "last_day_df['Days'] = last_day_df['Days'].apply(lambda x: x.days)\n",
    "last_day_df = last_day_df.loc[last_day_df['Days'] > 0]\n",
    "last_day_df[['location_id', 'ln(death rate)', 'Days']].to_csv(f'{OUTPUT_DIR}/last_day.csv', index=False)\n",
    "\n",
    "# read in data for cases-to-deaths\n",
    "cases_deaths_df = pd.read_csv(CASES_DEATHS_FILE)\n",
    "cases_deaths_df['Date'] = pd.to_datetime(cases_deaths_df['Date'])\n",
    "\n",
    "# run models\n",
    "submodel_dict = {}\n",
    "for location_id, location, country in zip(euro_df['location_id'], euro_df['Location'], euro_df['Country/Region']):\n",
    "    # run model\n",
    "    if location == country:\n",
    "        print(f'Running {location}')\n",
    "        mod_df = DeathModelData(input_death_df, input_age_pop_df, input_age_death_df, location_id, 'threshold', rate_threshold=RATE_THRESHOLD).df\n",
    "    else:\n",
    "        print(f'Running {country} -- {location}')\n",
    "        mod_df = DeathModelData(input_death_df, input_age_pop_df, input_age_death_df, location_id, 'threshold', subnat=True, rate_threshold=RATE_THRESHOLD).df\n",
    "    mod_df = mod_df.loc[~(mod_df['Deaths'].isnull())].reset_index(drop=True)\n",
    "    mod_df = mod_df.loc[~mod_df['Location'].isin(['Life Care Center, Kirkland, WA'])]\n",
    "    \n",
    "#     # Ugh, Miami needs to have location_id changed!\n",
    "#     # Change location_id for Miami\n",
    "#     miami = mod_df[mod_df['location_id'] == 60408]\n",
    "#     miami['location_id'] = 957\n",
    "#     mod_df = mod_df.append(miami)\n",
    "#     mod_df = mod_df[mod_df['location_id'] != 60408]\n",
    "    \n",
    "    # flag as true data\n",
    "    mod_df['pseudo'] = 0\n",
    "\n",
    "    # tack on deaths from cases if in dataset\n",
    "    if location_id in input_full_df['location_id'].tolist() and \\\n",
    "        location_id not in [84]:  # Ireland\n",
    "        # get future days\n",
    "        last_date = input_full_df.loc[input_full_df['location_id'] == location_id, 'Date'].max()\n",
    "        loc_cd_df = cases_deaths_df.loc[(cases_deaths_df['location_id'] == location_id) &\n",
    "                                        (cases_deaths_df['Date'] > last_date)].reset_index(drop=True)\n",
    "        loc_cd_df['population'] = input_full_df.loc[input_full_df['location_id'] == location_id,\n",
    "                                                    'population'].max()  # all the same...\n",
    "        loc_cd_df['pseudo'] = 1\n",
    "\n",
    "        if not loc_cd_df.empty:\n",
    "            # convert to days\n",
    "            if location_id in mod_df['location_id'].tolist():\n",
    "                last_day = mod_df.loc[mod_df['location_id'] == location_id, 'Days'].max()\n",
    "                loc_cd_df['Days'] = last_day + 1 + loc_cd_df.index\n",
    "            else:\n",
    "                threshold = date_mean_df.loc[date_mean_df['location_id'] == location_id, 'threshold_date'].item()\n",
    "                loc_cd_df['Days'] = loc_cd_df['Date'].apply(lambda x: (x - threshold).days)\n",
    "            loc_cd_df = loc_cd_df.loc[loc_cd_df['Days'] >= 0]\n",
    "\n",
    "            # stick on to dataset\n",
    "            mod_df = mod_df.append(loc_cd_df)\n",
    "            mod_df = mod_df.sort_values(['location_id', 'Days']).reset_index(drop=True)\n",
    "\n",
    "    # figure out which models we are running (will need to check about R0=1 model)\n",
    "    submodels = MOBILITY_SOURCES.copy()\n",
    "    submodel_dirs = get_out_dirs(submodels)\n",
    "\n",
    "    # how many draws for each\n",
    "    n_draws_list = get_draw_list(n_scenarios=len(submodel_dirs))\n",
    "\n",
    "    # store this information\n",
    "    submodel_dict.update({\n",
    "        int(location_id):{\n",
    "            'submodel_dirs':submodel_dirs,\n",
    "            'n_draws_list':n_draws_list\n",
    "        }\n",
    "    })\n",
    "\n",
    "    n_i = 0\n",
    "    for cov_source in MOBILITY_SOURCES:\n",
    "        if cov_source in MOBILITY_SOURCES:\n",
    "            covariate_effect = 'gamma'\n",
    "        else:\n",
    "            raise ValueError('Not expecting beta covariate at this time.')\n",
    "            covariate_effect = 'beta'\n",
    "        for k in KS:\n",
    "            # drop back-cast, and submit model\n",
    "            model_out_dir = f'{OUTPUT_DIR}/model_data_{cov_source}_{k}'\n",
    "            mod_df.to_csv(f'{model_out_dir}/{location_id}.csv', index=False)\n",
    "            sd_cov = SocialDistCov(mod_df, date_mean_df, data_version=DATA_VERSION)\n",
    "            if cov_source in MOBILITY_SOURCES:\n",
    "                sd_cov_df = sd_cov.get_cov_df(weights=[None], k=k, empirical_weight_source=cov_source)\n",
    "            else:\n",
    "                raise ValueError('Only expecting mobility weight model at this time.')\n",
    "                sd_cov_df = sd_cov.get_cov_df(weights=weights, k=k)\n",
    "            sd_cov_df.to_csv(f'{model_out_dir}/{location_id}_covariate.csv', index=False)\n",
    "            if not os.path.exists(f'{model_out_dir}/{location_id}'):\n",
    "                os.mkdir(f'{model_out_dir}/{location_id}')\n",
    "            submit_curvefit(job_name=f'curve_model_{location_id}_{cov_source}_{k}',\n",
    "                            location_id=location_id,\n",
    "                            code_dir=CODE_DIR,\n",
    "                            model_location_id=location_id,\n",
    "                            data_file=f'{model_out_dir}/{location_id}.csv',\n",
    "                            cov_file=f'{model_out_dir}/{location_id}_covariate.csv',\n",
    "                            last_day_file=f'{OUTPUT_DIR}/last_day.csv',\n",
    "                            peaked_file=PEAK_FILE,\n",
    "                            output_dir=f'{model_out_dir}/{location_id}',\n",
    "                            covariate_effect=covariate_effect,\n",
    "                            n_draws=n_draws_list[n_i],\n",
    "                            python=shutil.which('python'),\n",
    "                            verbose=False)\n",
    "            n_i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_df[mod_df['location_id'] == 60416]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_cov_df[sd_cov_df['location_id'] == 60411]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure Miami will merge.\n",
    "# Why are all the names different?! Whyyyyyyyy?\n",
    "# The problem is in the names in input_full_df\n",
    "date_df\n",
    "t = date_df[date_df['location_id'] == 957]\n",
    "t['location'] = 'Miami-Dade County'\n",
    "date_df = date_df.append(t)\n",
    "\n",
    "t = date_df[date_df['location_id'] == 60410]\n",
    "t['location'] = 'New York Metropolitan Area'\n",
    "date_df = date_df.append(t)\n",
    "\n",
    "t = date_df[date_df['location_id'] == 60416]\n",
    "t['location'] = 'UC Health'\n",
    "date_df = date_df.append(t)\n",
    "\n",
    "date_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile draws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# combine everything\n",
    "#date_df = pd.read_csv('/ihme/covid-19/deaths/dev/2020_04_22_Counties/threshold_dates.csv')\n",
    "draw_dfs = []\n",
    "past_draw_dfs = []\n",
    "models_used = []\n",
    "with PdfPages(f'{OUTPUT_DIR}/ensemble_plot.pdf') as pdf:\n",
    "    for location_id, location_name in zip(euro_df['location_id'], euro_df['Location']):\n",
    "        print(location_name)\n",
    "        peak_duration = 1\n",
    "        data_draws = Drawer(\n",
    "            ensemble_dirs=submodel_dict[int(location_id)]['submodel_dirs'],\n",
    "            n_draws_list=submodel_dict[int(location_id)]['n_draws_list'],\n",
    "            location_name=location_name,\n",
    "            location_id=int(location_id),\n",
    "            peak_duration=1,\n",
    "            obs_df=input_full_df[input_full_df['location_id'] == int(location_id)],\n",
    "            date_draws=date_df.loc[date_df['location'] == location_name, [i for i in date_df.columns if i.startswith('death_date_draw_')]].values,\n",
    "            population=input_age_pop_df.loc[input_age_pop_df['location_id'] == int(location_id), 'population'].sum(),\n",
    "        )\n",
    "        draw_df, past_draw_df, model_used, days, ensemble_draws = data_draws.get_dated_draws()\n",
    "        draw_dfs.append(draw_df)\n",
    "        past_draw_dfs.append(past_draw_df)\n",
    "        models_used.append(model_used)\n",
    "\n",
    "        # plot ensemble\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(11, 8.5))\n",
    "        for label, draws in ensemble_draws.items():\n",
    "            label = label.split('model_data_')[1]\n",
    "            draws = np.exp(draws) * input_age_pop_df.loc[input_age_pop_df['location_id'] == int(location_id), 'population'].sum()\n",
    "            deaths_mean = draws.mean(axis=0)\n",
    "            deaths_lower = np.percentile(draws, 2.5, axis=0)\n",
    "            deaths_upper = np.percentile(draws, 97.5, axis=0)\n",
    "\n",
    "            d_deaths_mean = (draws[:,1:] - draws[:,:-1]).mean(axis=0)\n",
    "            d_deaths_lower = np.percentile(draws[:,1:] - draws[:,:-1], 2.5, axis=0)\n",
    "            d_deaths_upper = np.percentile(draws[:,1:] - draws[:,:-1], 97.5, axis=0)\n",
    "\n",
    "            # cumulative\n",
    "            ax[0].fill_between(days,\n",
    "                               deaths_lower, deaths_upper,\n",
    "                               color=COLOR_DICT[label.split('_')[0]],\n",
    "                               linestyle=LINE_DICT[label.split('_')[1]],\n",
    "                               alpha=0.25)\n",
    "            ax[0].plot(days, deaths_mean,\n",
    "                       c=COLOR_DICT[label.split('_')[0]],\n",
    "                       linestyle=LINE_DICT[label.split('_')[1]], )\n",
    "            ax[0].set_title(f'constant: {k}')\n",
    "            ax[0].set_xlabel('Date')\n",
    "            ax[0].set_ylabel('Cumulative death rate')\n",
    "\n",
    "            # daily\n",
    "            ax[1].fill_between(days[1:],\n",
    "                               d_deaths_lower, d_deaths_upper,\n",
    "                               color=COLOR_DICT[label.split('_')[0]],\n",
    "                               linestyle=LINE_DICT[label.split('_')[1]],\n",
    "                               alpha=0.25)\n",
    "            ax[1].plot(days[1:], d_deaths_mean,\n",
    "                       c=COLOR_DICT[label.split('_')[0]],\n",
    "                       linestyle=LINE_DICT[label.split('_')[1]],\n",
    "                       label=label.replace('model_data_', ''))\n",
    "            ax[1].set_xlabel('Date')\n",
    "            ax[1].set_ylabel('Daily death rates')\n",
    "\n",
    "        ax[1].legend(loc=2)\n",
    "        plt.suptitle(f'{location_name} ({model_used})')\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "if 'location' not in models_used:\n",
    "    raise ValueError('No location-specific draws used, must be using wrong tag')\n",
    "draw_df = pd.concat(draw_dfs)\n",
    "model_type_df = pd.DataFrame({\n",
    "    'location':euro_df['Location'].to_list(),\n",
    "    'model_used':models_used\n",
    "})\n",
    "\n",
    "# write\n",
    "if 'draw_999' not in draw_df.columns:\n",
    "    draw_df['draw_999'] = draw_df['draw_998']\n",
    "\n",
    "draw_df.to_csv(f'{OUTPUT_DIR}/county_data.csv', index=False)\n",
    "model_type_df.to_csv(f'{OUTPUT_DIR}/county_models_used.csv', index=False)\n",
    "print(f'{OUTPUT_DIR}/countt_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_age_pop_df[input_age_pop_df['location_id']==957]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## combine with previous predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "# raw_draw_path = f'{OUTPUT_DIR}/euro_data.csv'\n",
    "# average_draw_path = f'{OUTPUT_DIR}/past_avg_euro_data.csv'\n",
    "# yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_17_Europe/euro_data.csv'\n",
    "# before_yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_16_Europe/euro_data.csv'\n",
    "## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "\n",
    "# Will this work?\n",
    "if combine_predictions:\n",
    "    avg_df = moving_average_predictions(\n",
    "        today_data_path=raw_draw_path,\n",
    "        yesterday_data_path=yesterday_draw_path,\n",
    "        day_before_yesterday_path=before_yesterday_draw_path\n",
    "    )\n",
    "    avg_df['date'] = pd.to_datetime(avg_df['date'])\n",
    "    past_draw_df = pd.concat(past_draw_dfs)\n",
    "\n",
    "    ## NO NEED TO DO THIS, FOR NOW ##\n",
    "    # avg_df = get_peak_date(past_draw_df, avg_df)\n",
    "\n",
    "    # store data\n",
    "    avg_df.to_csv(average_draw_path, index=False)\n",
    "    print(average_draw_path)\n",
    "\n",
    "    # plot\n",
    "    plotter = CompareAveragingModelDeaths(\n",
    "        raw_draw_path=raw_draw_path,\n",
    "        average_draw_path=average_draw_path,\n",
    "        yesterday_draw_path=yesterday_draw_path,\n",
    "        before_yesterday_draw_path=before_yesterday_draw_path\n",
    "        )\n",
    "    plotter.make_some_pictures(f'{OUTPUT_DIR}/moving_average_compare.pdf',\n",
    "                                'EEA + Australia + New Zealand')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plotter = CompareModelDeaths(\n",
    "    old_draw_path='/ihme/covid-19/deaths/dev/2020_04_22_Counties/county_data.csv',\n",
    "    new_draw_path='/ihme/covid-19/deaths/dev/2020_04_22_Counties/county_data.csv'\n",
    ")\n",
    "plotter.make_some_pictures(f'{OUTPUT_DIR}/compare_to_previous.pdf',\n",
    "                           'EEA + others')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "viz_dir = f'/home/j/Project/covid/results/diagnostics/deaths/{DATESTAMP_LABEL}_Counties/'\n",
    "if not os.path.exists(viz_dir):\n",
    "    os.mkdir(viz_dir)\n",
    "for viz_fp in ['compare_to_previous.pdf','ensemble_plot.pdf']: #'moving_average_compare.pdf']:\n",
    "    shutil.copyfile(src=f\"{OUTPUT_DIR}/{viz_fp}\", dst=f\"{viz_dir}/{viz_fp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(viz_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
