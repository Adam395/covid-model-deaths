{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from datetime import datetime, timedelta\n",
    "from multiprocessing import Pool\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 99\n",
    "pd.options.display.max_columns = 99\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from covid_model_deaths.data import get_input_data, plot_crude_rates, DeathModelData\n",
    "from covid_model_deaths.social_distancing_cov import SocialDistCov\n",
    "from covid_model_deaths.drawer import Drawer\n",
    "from covid_model_deaths.utilities import CompareModelDeaths, MOBILITY_SOURCES, KS, RATE_THRESHOLD, submit_curvefit, get_peak_date\n",
    "from covid_model_deaths.impute_death_threshold import impute_death_threshold\n",
    "from covid_model_deaths.moving_average import moving_average_predictions\n",
    "from covid_model_deaths.compare_moving_average import CompareAveragingModelDeaths\n",
    "\n",
    "from db_queries import get_location_metadata\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "RUN_TYPE = 'prod'\n",
    "DATESTAMP_LABEL = '2020_04_17_US'\n",
    "DATA_VERSION = 'best'\n",
    "PEAK_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_14/final_peak_locs_04_14.csv'\n",
    "CASES_DEATHS_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_14/deaths_from_cases.csv'\n",
    "# PEAK_DURATION_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_14/smooth_peak_duration.csv'\n",
    "# R0_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_14/R0_dates.csv'\n",
    "\n",
    "# ensemble plot settings\n",
    "COLOR_DICT = {\n",
    "    'safegraph':'dodgerblue',\n",
    "    'google':'forestgreen',\n",
    "    'descartes':'firebrick',\n",
    "    # 'R0_35':'gold',\n",
    "    # 'R0_50':'darkgrey',\n",
    "    # 'R0_65':'darkviolet'\n",
    "}\n",
    "LINE_DICT = {\n",
    "    #'14':'-',\n",
    "    '21':'--'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_DIR = os.path.abspath('../src/covid_model_deaths')\n",
    "OUTPUT_DIR = f'/ihme/covid-19/deaths/{RUN_TYPE}/{DATESTAMP_LABEL}'\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "print(f'Writing to {OUTPUT_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CODE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read full (unrestricted) set from snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# come up with more informative names...\n",
    "input_full_df = get_input_data('full_data', DATA_VERSION)\n",
    "input_death_df = get_input_data('deaths', DATA_VERSION)\n",
    "# # Dropping recent Montana data due to slow growth resulting in implausible backcast\n",
    "# input_death_df = input_death_df.loc[(input_death_df['Location']!=\"Montana\") | (input_death_df['Date'] < pd.Timestamp(\"2020-04-01\"))]\n",
    "input_age_pop_df = get_input_data('age_pop', DATA_VERSION)\n",
    "input_age_death_df = get_input_data('age_death', DATA_VERSION)\n",
    "\n",
    "# drop Georgia the country until we fix location_ids\n",
    "input_full_df = input_full_df[input_full_df['Country/Region'] != 'Georgia'].reset_index(drop=True)\n",
    "input_death_df = input_death_df[input_death_df['Country/Region'] != 'Georgia'].reset_index(drop=True)\n",
    "\n",
    "# # read in cov input file (predicted date of R0 == 1) to see if we are using these for a given location\n",
    "# cov_df = pd.read_csv(R0_FILE)\n",
    "# r0_locs = cov_df['location_id'].unique().tolist()\n",
    "# del cov_df\n",
    "r0_locs = []\n",
    "\n",
    "# # less conservative peak ranges\n",
    "# peak_dur_df = pd.read_csv(PEAK_DURATION_FILE)\n",
    "# peak_dur_df = peak_dur_df.loc[peak_dur_df['Location'] != 'Colorado']\n",
    "# peak_dur_df['peak start date'] = pd.to_datetime(peak_dur_df['peak start date'])\n",
    "# peak_dur_df['peak end date'] = pd.to_datetime(peak_dur_df['peak end date'])\n",
    "\n",
    "# plot\n",
    "plot_crude_rates(input_death_df, level='subnat')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04/16 - crazy numbers in NY, drop today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_full_df = input_full_df.loc[(input_full_df['Province/State'] != 'New York') | \n",
    "                                  (input_full_df['Date'] < pd.Timestamp('2020-04-16'))]\n",
    "input_death_df = input_death_df.loc[(input_death_df['Location'] != 'New York') | \n",
    "                                    (input_death_df['Date'] < pd.Timestamp('2020-04-16'))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store pops for bobby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_input_data('us_pops').to_csv(f'{OUTPUT_DIR}/pops.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine back-casted death rates with cases for abie (using model dataset, i.e. admin1 and below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "location_ids = sorted(input_full_df.loc[(np.log(input_full_df['Death rate']) > RATE_THRESHOLD) &\n",
    "                                        (~input_full_df['Province/State'].isnull()), \n",
    "                                        'location_id'].unique())\n",
    "\n",
    "start_time = datetime.now()\n",
    "def combine_cases_w_backcast_deaths(location_id, input_death_df, input_age_pop_df, input_age_death_df, rate_threshold):\n",
    "    mod_df = DeathModelData(input_death_df, input_age_pop_df, input_age_death_df, location_id, 'threshold', subnat=True, rate_threshold=RATE_THRESHOLD).df\n",
    "    mod_df = mod_df.loc[mod_df['location_id'] == location_id].reset_index(drop=True)\n",
    "    if len(mod_df) > 0:\n",
    "        date0 = mod_df['Date'].min()\n",
    "        day0 = mod_df.loc[~mod_df['Date'].isnull(), 'Days'].min()\n",
    "        mod_df.loc[mod_df['Days'] == 0, 'Date'] = date0 - timedelta(days=np.round(day0))\n",
    "        mod_df = mod_df.loc[~((mod_df['Deaths'].isnull()) & (mod_df['Date'] == date0))]\n",
    "        mod_df = mod_df.loc[~mod_df['Date'].isnull()]\n",
    "        mod_df.loc[mod_df['Death rate'].isnull(), 'Death rate'] = np.exp(mod_df['ln(age-standardized death rate)'])\n",
    "        mod_df.loc[mod_df['Deaths'].isnull(), 'Deaths'] = mod_df['Death rate'] * mod_df['population']\n",
    "        mod_df = mod_df.rename(index=str, columns={'Location':'Province/State'})\n",
    "    else:\n",
    "        mod_df = pd.DataFrame(\n",
    "            columns=['location_id', 'Province/State', 'Country/Region', 'Date', 'Deaths', 'Death rate', 'population']\n",
    "        )\n",
    "\n",
    "    return mod_df[['location_id', 'Province/State', 'Country/Region', 'Date', 'Deaths', 'Death rate', 'population']].reset_index(drop=True)\n",
    "\n",
    "_combiner = functools.partial(combine_cases_w_backcast_deaths, \n",
    "                              input_death_df=input_death_df, \n",
    "                              input_age_pop_df=input_age_pop_df, \n",
    "                              input_age_death_df=input_age_death_df, \n",
    "                              rate_threshold=RATE_THRESHOLD)\n",
    "pool = Pool(20)\n",
    "loc_dfs = pool.map(_combiner, location_ids)\n",
    "pool.close()\n",
    "pool.join()\n",
    "loc_df = pd.concat(loc_dfs)\n",
    "loc_df = input_full_df[['location_id', 'Province/State', 'Country/Region', 'Date', 'Confirmed', 'Confirmed case rate']].merge(\n",
    "    loc_df, how='outer'\n",
    ").reset_index(drop=True)\n",
    "loc_df.loc[loc_df['Province/State'].isnull(), 'Province/State'] = loc_df['Country/Region']\n",
    "loc_df['location_id'] = loc_df['location_id'].astype(int)\n",
    "loc_df.to_csv(f'{OUTPUT_DIR}/backcast_for_case_to_death.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = impute_death_threshold(loc_df,\n",
    "                                 location_list=loc_df.loc[(loc_df['Country/Region'] == 'United States of America') &\n",
    "                                                          (~loc_df['Province/State'].isnull()), 'Province/State'].unique().tolist(),\n",
    "                                 ln_death_rate_threshold=RATE_THRESHOLD)\n",
    "loc_df = loc_df[['location_id', 'Province/State']].drop_duplicates()\n",
    "loc_df = loc_df.rename(index=str, columns={'Province/State':'location'})\n",
    "date_df = loc_df.merge(date_df)\n",
    "date_df.to_csv(f'{OUTPUT_DIR}/threshold_dates.csv', index=False)\n",
    "del loc_df\n",
    "end_time = datetime.now()\n",
    "print(end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create datasets for each subnational unit of US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get location information\n",
    "loc_df = get_location_metadata(location_set_id=35, gbd_round_id=6)\n",
    "location_ids = loc_df.loc[(loc_df['parent_id'] == 102) & (loc_df['location_name'] != 'Washington'), \n",
    "                          'location_id'].to_list()\n",
    "location_names = loc_df.loc[(loc_df['parent_id'] == 102) & (loc_df['location_name'] != 'Washington'), \n",
    "                           'location_name'].to_list()\n",
    "for wa_location in ['Other Counties, WA',\n",
    "                    'King and Snohomish Counties (excluding Life Care Center), WA', \n",
    "                    'Life Care Center, Kirkland, WA']:\n",
    "    location_ids += [input_full_df.loc[input_full_df['Province/State'] == wa_location, 'location_id'].astype(int).unique().item()]\n",
    "    location_names += [wa_location]\n",
    "\n",
    "## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "## NEED TO ADD OPTION TO ADD NEW YORK + MIAMI (UNTIL WE MOVE TO LOCATION HIERARCHY)\n",
    "## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "\n",
    "# method for getting dates\n",
    "def date_mean(dates):\n",
    "    dt_min = dates.min()\n",
    "    deltas = [x-dt_min for x in dates]\n",
    "\n",
    "    return dt_min + functools.reduce(operator.add, deltas) / len(deltas)\n",
    "\n",
    "# get mean data from dataset\n",
    "date_draws = [i for i in date_df.columns if i.startswith('death_date_draw_')]\n",
    "date_mean_df = date_df.copy()\n",
    "date_mean_df['threshold_date'] = date_mean_df.apply(\n",
    "    lambda x: datetime.strptime(date_mean(x[date_draws]).strftime('%Y-%m-%d'), '%Y-%m-%d'),\n",
    "    axis=1\n",
    ")\n",
    "date_mean_df['Country/Region'] = 'United States of America'\n",
    "date_mean_df = date_mean_df.rename(index=str, columns={'location':'Location'})\n",
    "date_mean_df = date_mean_df[['location_id', 'Location', 'Country/Region', 'threshold_date']]\n",
    "\n",
    "# set up ensemble\n",
    "def get_out_dirs(model_labels):\n",
    "    model_out_dirs = []\n",
    "    for model_label in model_labels:\n",
    "        for k in KS:\n",
    "            # set up dirs\n",
    "            model_out_dir = f'{OUTPUT_DIR}/model_data_{model_label}_{k}'\n",
    "            if not os.path.exists(model_out_dir):\n",
    "                os.mkdir(model_out_dir)\n",
    "            model_out_dirs.append(model_out_dir)\n",
    "            \n",
    "    return model_out_dirs\n",
    "def get_draw_list(n_scenarios):\n",
    "    n_draws_list = [int(1000 / n_scenarios)] * n_scenarios\n",
    "    n_draws_list[-1] = n_draws_list[-1] + 1000 - np.sum(n_draws_list)\n",
    "    \n",
    "    return n_draws_list\n",
    "\n",
    "# prepare last day dataset\n",
    "last_day_df = input_full_df.copy()\n",
    "last_day_df['last_day'] = last_day_df.groupby('location_id', as_index=False)['Date'].transform(max)\n",
    "last_day_df = last_day_df.loc[last_day_df['Date'] == last_day_df['last_day']].reset_index(drop=True)\n",
    "last_day_df['location_id'] = last_day_df['location_id'].astype(int)\n",
    "last_day_df.loc[last_day_df['Death rate'] == 0, 'Death rate'] = 0.1 / last_day_df['population']\n",
    "last_day_df['ln(death rate)'] = np.log(last_day_df['Death rate'])\n",
    "last_day_df = last_day_df[['location_id', 'ln(death rate)', 'Date']].merge(date_mean_df)\n",
    "last_day_df['Days'] = (last_day_df['Date'] - last_day_df['threshold_date'])\n",
    "last_day_df['Days'] = last_day_df['Days'].apply(lambda x: x.days)\n",
    "last_day_df = last_day_df.loc[last_day_df['Days'] > 0]\n",
    "last_day_df[['location_id', 'ln(death rate)', 'Days']].to_csv(f'{OUTPUT_DIR}/last_day.csv', index=False)\n",
    "\n",
    "# read in data for cases-to-deaths\n",
    "cases_deaths_df = pd.read_csv(CASES_DEATHS_FILE)\n",
    "cases_deaths_df['Date'] = pd.to_datetime(cases_deaths_df['Date'])\n",
    "\n",
    "# submit models\n",
    "submodel_dict = {}\n",
    "N = len(location_ids)\n",
    "i = 0\n",
    "nursing_home_locations = ['Life Care Center, Kirkland, WA']\n",
    "for location_id, location_name in zip(location_ids, location_names):\n",
    "    i += 1\n",
    "    print(f'{i} / {N} locations')\n",
    "    mod = DeathModelData(input_death_df, input_age_pop_df, input_age_death_df, location_id, 'threshold', subnat=True, rate_threshold=RATE_THRESHOLD)\n",
    "    if location_name in nursing_home_locations:\n",
    "        # save only nursing homes\n",
    "        mod_df = mod.df.copy()\n",
    "    else:\n",
    "        # save only others\n",
    "        mod_df = mod.df.loc[~mod.df['Location'].isin(nursing_home_locations)].reset_index(drop=True)\n",
    "    # drop back-cast\n",
    "    mod_df = mod_df.loc[~(mod_df['Deaths'].isnull())].reset_index(drop=True)\n",
    "    \n",
    "    # flag as true data\n",
    "    mod_df['pseudo'] = 0\n",
    "    \n",
    "    # tack on deaths from cases if in dataset\n",
    "    if location_id in input_full_df['location_id'].tolist() and \\\n",
    "        location_id not in [564, 538]:  # South Dakota, Iowa\n",
    "        # get future days\n",
    "        last_date = input_full_df.loc[input_full_df['location_id'] == location_id, 'Date'].max()\n",
    "        loc_cd_df = cases_deaths_df.loc[(cases_deaths_df['location_id'] == location_id) &\n",
    "                                        (cases_deaths_df['Date'] > last_date)].reset_index(drop=True)\n",
    "        loc_cd_df['population'] = input_full_df.loc[input_full_df['location_id'] == location_id, \n",
    "                                                    'population'].max()  # all the same...\n",
    "        loc_cd_df['pseudo'] = 1\n",
    "        \n",
    "        # convert to days\n",
    "        if location_id in mod_df['location_id'].tolist():\n",
    "            last_day = mod_df.loc[mod_df['location_id'] == location_id, 'Days'].max()\n",
    "            loc_cd_df['Days'] = last_day + 1 + loc_cd_df.index\n",
    "        else:\n",
    "            threshold = date_mean_df.loc[date_mean_df['location_id'] == location_id, 'threshold_date'].item()\n",
    "            loc_cd_df['Days'] = loc_cd_df['Date'].apply(lambda x: (x - threshold).days)\n",
    "        loc_cd_df = loc_cd_df.loc[loc_cd_df['Days'] >= 0]\n",
    "            \n",
    "        # stick on to dataset\n",
    "        mod_df = mod_df.append(loc_cd_df)\n",
    "        mod_df = mod_df.sort_values(['location_id', 'Days']).reset_index(drop=True)\n",
    "    \n",
    "    # figure out which models we are running (will need to check about R0=1 model)\n",
    "    submodels = MOBILITY_SOURCES.copy()\n",
    "    if location_id in r0_locs:\n",
    "        submodels += ['R0_35', 'R0_50', 'R0_65']\n",
    "    submodel_dirs = get_out_dirs(submodels)\n",
    "    \n",
    "    # how many draws for each\n",
    "    n_draws_list = get_draw_list(n_scenarios=len(submodel_dirs))\n",
    "    \n",
    "    # store this information\n",
    "    submodel_dict.update({\n",
    "        int(location_id):{\n",
    "            'submodel_dirs':submodel_dirs,\n",
    "            'n_draws_list':n_draws_list\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    # run models\n",
    "    n_i = 0\n",
    "    for cov_source in submodels:\n",
    "        if cov_source in MOBILITY_SOURCES:\n",
    "            covariate_effect = 'gamma'\n",
    "        else:\n",
    "            covariate_effect = 'beta'\n",
    "        for k in KS:\n",
    "            # drop back-cast for modeling file, but NOT for the social distancing covariate step\n",
    "            model_out_dir = f'{OUTPUT_DIR}/model_data_{cov_source}_{k}'\n",
    "            mod_df.to_csv(f'{model_out_dir}/{location_name}.csv', index=False)\n",
    "            sd_cov = SocialDistCov(mod_df, date_mean_df, data_version=DATA_VERSION)\n",
    "            if cov_source in MOBILITY_SOURCES:\n",
    "                sd_cov_df = sd_cov.get_cov_df(weights=[None], k=k, empirical_weight_source=cov_source)\n",
    "            else:\n",
    "                sd_cov_df = sd_cov.get_cov_df(weights=[None], k=k, empirical_weight_source=cov_source, R0_file=R0_FILE)\n",
    "            sd_cov_df.to_csv(f'{model_out_dir}/{location_name} covariate.csv', index=False)\n",
    "            if not os.path.exists(f'{model_out_dir}/{location_name}'):\n",
    "                os.mkdir(f'{model_out_dir}/{location_name}')\n",
    "            submit_curvefit(job_name=f'curve_model_{location_id}_{cov_source}_{k}',\n",
    "                            location_id=location_id, \n",
    "                            code_dir=CODE_DIR,\n",
    "                            model_location=location_name,\n",
    "                            model_location_id=location_id,\n",
    "                            data_file=f'{model_out_dir}/{location_name}.csv', \n",
    "                            cov_file=f'{model_out_dir}/{location_name} covariate.csv', \n",
    "                            last_day_file=f'{OUTPUT_DIR}/last_day.csv',\n",
    "                            peaked_file=PEAK_FILE,\n",
    "                            output_dir=f'{model_out_dir}/{location_name}',\n",
    "                            covariate_effect=covariate_effect,\n",
    "                            n_draws=n_draws_list[n_i],\n",
    "                            python=shutil.which('python'),\n",
    "                            verbose=False)\n",
    "            n_i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset US\n",
    "usa_obs_df = input_full_df[(input_full_df['Country/Region'] == 'United States of America') & \n",
    "                           (~input_full_df['Province/State'].isnull())]\n",
    "\n",
    "# combine everything\n",
    "draw_dfs = []\n",
    "past_draw_dfs = []\n",
    "models_used = []\n",
    "with PdfPages(f'{OUTPUT_DIR}/ensemble_plot.pdf') as pdf:\n",
    "    for location_id, location_name in zip(location_ids, location_names):\n",
    "        # # identify peak duration\n",
    "        # if int(location_id) in peak_dur_df['location_id'].to_list():\n",
    "        #     print(f'{location_name}: observed peak')\n",
    "        #     peak_duration = peak_dur_df.loc[peak_dur_df['location_id'] == int(location_id), 'peak durations'].item()\n",
    "        # else:\n",
    "        #     print(f'{location_name}: average peak')\n",
    "        #     peak_duration = 5\n",
    "        # peak_duration = int(np.round(peak_duration))\n",
    "        # print(f'Peak length: {peak_duration}')\n",
    "        peak_duration = 1\n",
    "        # get draws\n",
    "        data_draws = Drawer(\n",
    "            ensemble_dirs=submodel_dict[int(location_id)]['submodel_dirs'],\n",
    "            n_draws_list=submodel_dict[int(location_id)]['n_draws_list'],\n",
    "            location_name=location_name, \n",
    "            location_id=int(location_id), \n",
    "            peak_duration=peak_duration,\n",
    "            obs_df=usa_obs_df.loc[usa_obs_df['location_id'] == int(location_id)],\n",
    "            date_draws=date_df.loc[date_df['location'] == location_name, date_draws].values, \n",
    "            population=input_age_pop_df.loc[input_age_pop_df['location_id'] == int(location_id), 'population'].sum()\n",
    "        )\n",
    "        draw_df, past_draw_df, model_used, days, ensemble_draws = data_draws.get_dated_draws()\n",
    "        draw_dfs.append(draw_df)\n",
    "        past_draw_dfs.append(past_draw_df)\n",
    "        models_used.append(model_used)\n",
    "\n",
    "        # plot ensemble\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(11, 8.5))\n",
    "        for label, draws in ensemble_draws.items():\n",
    "            label = label.split('model_data_')[1]\n",
    "            draws = np.exp(draws) * input_age_pop_df.loc[input_age_pop_df['location_id'] == int(location_id), 'population'].sum()\n",
    "            deaths_mean = draws.mean(axis=0)\n",
    "            deaths_lower = np.percentile(draws, 2.5, axis=0)\n",
    "            deaths_upper = np.percentile(draws, 97.5, axis=0)\n",
    "\n",
    "            d_deaths_mean = (draws[:,1:] - draws[:,:-1]).mean(axis=0)\n",
    "            d_deaths_lower = np.percentile(draws[:,1:] - draws[:,:-1], 2.5, axis=0)\n",
    "            d_deaths_upper = np.percentile(draws[:,1:] - draws[:,:-1], 97.5, axis=0)\n",
    "\n",
    "            # cumulative\n",
    "            ax[0].fill_between(days,\n",
    "                               deaths_lower, deaths_upper,\n",
    "                               color=COLOR_DICT['_'.join(label.split('_')[:-1])], \n",
    "                               linestyle=LINE_DICT[label.split('_')[-1]], \n",
    "                               alpha=0.25)\n",
    "            ax[0].plot(days, deaths_mean, \n",
    "                       c=COLOR_DICT['_'.join(label.split('_')[:-1])], \n",
    "                       linestyle=LINE_DICT[label.split('_')[-1]])\n",
    "            ax[0].set_xlabel('Date')\n",
    "            ax[0].set_ylabel('Cumulative death rate')\n",
    "\n",
    "            # daily\n",
    "            ax[1].fill_between(days[1:],\n",
    "                               d_deaths_lower, d_deaths_upper,\n",
    "                               color=COLOR_DICT['_'.join(label.split('_')[:-1])], \n",
    "                               linestyle=LINE_DICT[label.split('_')[-1]], \n",
    "                               alpha=0.25)\n",
    "            ax[1].plot(days[1:], d_deaths_mean, \n",
    "                       c=COLOR_DICT['_'.join(label.split('_')[:-1])], \n",
    "                       linestyle=LINE_DICT[label.split('_')[-1]], \n",
    "                       label=label.replace('model_data_', ''))\n",
    "            ax[1].set_xlabel('Date')\n",
    "            ax[1].set_ylabel('Daily death rates')\n",
    "\n",
    "        ax[1].legend(loc=2)\n",
    "        plt.suptitle(f'{location_name} ({model_used})')\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "if 'location' not in models_used:\n",
    "    raise ValueError('No location-specific draws used, must be using wrong tag')\n",
    "draw_df = pd.concat(draw_dfs)\n",
    "model_type_df = pd.DataFrame({\n",
    "    'location':location_names,\n",
    "    'model_used':models_used\n",
    "})\n",
    "\n",
    "# write\n",
    "draw_df.to_csv(f'{OUTPUT_DIR}/state_data.csv', index=False)\n",
    "model_type_df.to_csv(f'{OUTPUT_DIR}/state_models_used.csv', index=False)\n",
    "print(f'{OUTPUT_DIR}/state_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total US deaths in this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_cols = [f'draw_{i}' for i in range(1000)]\n",
    "nat_df = draw_df.groupby('date', as_index=False)[draw_cols].sum()\n",
    "nat_df = nat_df.loc[nat_df['date'] == pd.Timestamp('2020-07-15')]\n",
    "deaths_mean = int(nat_df[draw_cols].mean(axis=1).item())\n",
    "deaths_lower = int(np.percentile(nat_df[draw_cols], 2.5, axis=1).item())\n",
    "deaths_upper = int(np.percentile(nat_df[draw_cols], 97.5, axis=1).item())\n",
    "f'{deaths_mean:,} ({deaths_lower:,} - {deaths_upper:,})'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine with previous predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "# raw_draw_path = f'{OUTPUT_DIR}/state_data.csv'\n",
    "# average_draw_path = f'{OUTPUT_DIR}/past_avg_state_data.csv'\n",
    "# yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_10_US/state_data.csv'\n",
    "# before_yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_09_US/state_data.csv'\n",
    "# ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "\n",
    "# avg_df = moving_average_predictions(\n",
    "#     'US', \n",
    "#     specified=True,\n",
    "#     model_1=raw_draw_path,\n",
    "#     model_2=yesterday_draw_path,\n",
    "#     model_3=before_yesterday_draw_path\n",
    "# )\n",
    "# avg_df['date'] = pd.to_datetime(avg_df['date'])\n",
    "# past_draw_df = pd.concat(past_draw_dfs)\n",
    "\n",
    "# ## NO NEED TO DO THIS, FOR NOW ##\n",
    "# # avg_df = get_peak_date(past_draw_df, avg_df)\n",
    "\n",
    "# # store data\n",
    "# avg_df.to_csv(average_draw_path, index=False)\n",
    "# print(average_draw_path)\n",
    "\n",
    "# # plot\n",
    "# plotter = CompareAveragingModelDeaths(\n",
    "#     raw_draw_path=raw_draw_path,\n",
    "#     average_draw_path=average_draw_path,\n",
    "#     yesterday_draw_path=yesterday_draw_path,\n",
    "#     before_yesterday_draw_path=before_yesterday_draw_path\n",
    "#     )\n",
    "# plotter.make_some_pictures(f'{OUTPUT_DIR}/moving_average_compare.pdf',\n",
    "#                            'United States of America')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = CompareModelDeaths(\n",
    "    old_draw_path='/ihme/covid-19/deaths/prod/2020_04_16_US/state_data.csv',\n",
    "    new_draw_path=f'{OUTPUT_DIR}/state_data.csv'\n",
    ")\n",
    "plotter.make_some_pictures(f'{OUTPUT_DIR}/compare_to_previous.pdf',\n",
    "                           'United States of America')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viz_dir = f'/home/j/Project/covid/results/diagnostics/deaths/{DATESTAMP_LABEL}/'\n",
    "if not os.path.exists(viz_dir):\n",
    "    os.mkdir(viz_dir)\n",
    "for viz_fp in ['compare_to_previous.pdf','ensemble_plot.pdf']:  # ,'moving_average_compare.pdf'\n",
    "    shutil.copyfile(src=f\"{OUTPUT_DIR}/{viz_fp}\", dst=f\"{viz_dir}/{viz_fp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(viz_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
