{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../')\n",
    "from data import nCovid19Deaths\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "DATESTAMP_LABEL = '2020_03_30'\n",
    "\n",
    "# just use generic name since the location names include non-alphanumeric characters  # -l archive=TRUE \n",
    "QSUB_STR = 'qsub -N curve_model_{location_id} -P proj_covid -q d.q -l m_mem_free=3G -l fthread=3 -o omp_num_threads=3 '\\\n",
    "    '{code_dir}/mr_brt_refactor_env.sh {code_dir}/model.py '\\\n",
    "    '--model_location {model_location} --data_file {data_file} --cov_file {cov_file} --output_dir {output_dir}'\n",
    "CODE_DIR = os.path.abspath('')\n",
    "OUTPUT_DIR = f'/ihme/covid-19/deaths/counterfactual/{DATESTAMP_LABEL}'\n",
    "CASE_DIR = f'/ihme/covid-19/deaths/counterfactual/cases_{DATESTAMP_LABEL}'\n",
    "DEATH_FILE = f'/ihme/code/dbd/hkl1/covid_19_model/model_data/state_data_{DATESTAMP_LABEL}.csv'\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "print(f'Writing to {OUTPUT_DIR}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in case and death data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily cases\n",
    "locations = [i[:-4] for i in os.listdir(CASE_DIR) if i.endswith('.csv')]\n",
    "case_df = pd.concat([\n",
    "    pd.read_csv(f'{CASE_DIR}/{location}.csv') for location in locations\n",
    "]).reset_index(drop=True)\n",
    "case_df['date'] = case_df['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "case_df['cases'] = case_df[[f'draw_{i}' for i in range(1000)]].mean(axis=1)\n",
    "case_df = case_df[['location', 'date', 'cases']]\n",
    "case_df = case_df.sort_values(['location', 'date']).reset_index(drop=True)\n",
    "\n",
    "# cumulative deaths\n",
    "death_draws_df = pd.read_csv(DEATH_FILE)\n",
    "death_draws_df['date'] = death_draws_df['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "death_df = death_draws_df.copy()\n",
    "death_df['deaths'] = death_df[[f'draw_{i}' for i in range(1000)]].mean(axis=1)\n",
    "death_df = death_df[['location', 'date', 'deaths']]\n",
    "death_df = death_df.sort_values(['location', 'date']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upswing_deaths(location, loc_case_df, loc_death_df):\n",
    "    may1_cases = loc_case_df.loc[loc_case_df['date'] == datetime.strptime('2020-05-01', '%Y-%m-%d'), 'cases'].item()\n",
    "\n",
    "    if may1_cases >= 1:\n",
    "        ## get date of that number of cases on upswing:\n",
    "        ##     find peak, get diff in cases before that time, argmin\n",
    "        peak_idx = loc_case_df['cases'].values.argmax()\n",
    "        upswing_date = loc_case_df.iloc[np.abs(loc_case_df['cases'].values - may1_cases)[:peak_idx].argmin()]['date']\n",
    "        upswing_cases = loc_case_df.iloc[np.abs(loc_case_df['cases'].values - may1_cases)[:peak_idx].argmin()]['cases']\n",
    "        loc_death_df = loc_death_df.loc[loc_death_df['date'] <= upswing_date]\n",
    "        if len(loc_death_df) > 0:\n",
    "            # fix if estimate is < truth (can happen if below threshold)\n",
    "            loc_death_df.loc[loc_death_df['deaths'] < loc_death_df['deaths'].values[0], 'deaths'] = loc_death_df['deaths'].values[0]\n",
    "            if loc_death_df['deaths'].min() == loc_death_df['deaths'].max():\n",
    "                print(f'No change in deaths for {location}')\n",
    "                loc_death_df = loc_death_df.loc[loc_death_df['deaths'] < loc_death_df['deaths'].min()]\n",
    "        ## make a picture\n",
    "        # plt.plot(loc_case_df['date'], loc_case_df['cases'], color='blue')\n",
    "        # plt.axhline(may1_cases, color='green', alpha=0.75, linestyle='--')\n",
    "        # plt.axhline(upswing_cases, color='red', alpha=0.75, linestyle='--')\n",
    "        # plt.axvline(datetime.strptime('2020-05-01', '%Y-%m-%d'), color='green', alpha=0.75, linestyle='--')\n",
    "        # plt.axvline(upswing_date, color='red', alpha=0.75, linestyle='--')\n",
    "        # plt.title(location)\n",
    "        # plt.show()\n",
    "    else:\n",
    "        print(f'No new cases on May 1 for {location}')\n",
    "        loc_death_df = pd.DataFrame(columns=loc_death_df.columns)\n",
    "    \n",
    "    # convert to days\n",
    "    loc_death_df['days'] = loc_death_df['date'].apply(lambda x: (x - loc_death_df['date'].min()).days)\n",
    "    \n",
    "    return loc_death_df\n",
    "\n",
    "# do the thing\n",
    "upswing_df = pd.concat([\n",
    "    get_upswing_deaths(\n",
    "        location=location,\n",
    "        loc_case_df=case_df.loc[case_df['location'] == location].reset_index(drop=True),\n",
    "        loc_death_df=death_df.loc[death_df['location'] == location].reset_index(drop=True)\n",
    "    ) for location in locations\n",
    "]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get necessary info for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nCovid19Deaths(data_version='best')\n",
    "data.collect_data()\n",
    "pop_df = data.age_pop_df.merge(data.df[['location_id', 'Province/State']].drop_duplicates())\n",
    "del data\n",
    "pop_df = pop_df.rename(index=str, columns={'Province/State':'location'})\n",
    "pop_df = pop_df.groupby(['location_id', 'location'], as_index=False)['population'].sum()\n",
    "upswing_df = upswing_df.merge(pop_df)\n",
    "del pop_df\n",
    "upswing_df['ln(age-standardized death rate)'] = np.log(upswing_df['deaths'] / upswing_df['population'])\n",
    "upswing_df = upswing_df.rename(\n",
    "    index=str,\n",
    "    columns={'location':'Location',\n",
    "             'deaths':'Deaths',\n",
    "             'days':'Days',\n",
    "             'date':'Date'}\n",
    ")\n",
    "pd.merge(\n",
    "    upswing_df.groupby('Location', as_index=False)['Days'].count(),\n",
    "    upswing_df.groupby('Location', as_index=False)['ln(age-standardized death rate)'].min()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_curvefit(location_id, model_location, data_file, cov_file, output_dir):\n",
    "    qsub_str = QSUB_STR.format(\n",
    "        location_id=location_id,\n",
    "        code_dir=CODE_DIR,\n",
    "        model_location=model_location.replace(' ', '\\ ').replace('(', '\\(').replace(')', '\\)'),\n",
    "        data_file=data_file.replace(' ', '\\ ').replace('(', '\\(').replace(')', '\\)'),\n",
    "        cov_file=cov_file.replace(' ', '\\ ').replace('(', '\\(').replace(')', '\\)'),\n",
    "        output_dir=output_dir.replace(' ', '\\ ').replace('(', '\\(').replace(')', '\\)')\n",
    "    )\n",
    "    \n",
    "    job_str = os.popen(qsub_str).read()\n",
    "    print(job_str)\n",
    "\n",
    "model_out_dir = f'{OUTPUT_DIR}/model_data'\n",
    "if not os.path.exists(model_out_dir):\n",
    "    os.mkdir(model_out_dir)\n",
    "\n",
    "# store deaths (ONLY KEEP ABOVE THRESHOLD!!!!)\n",
    "upswing_df = upswing_df.loc[upswing_df['ln(age-standardized death rate)'] >= -15]\n",
    "upswing_df.to_csv(f'{model_out_dir}/us_deaths.csv', index=False)\n",
    "\n",
    "# create dummy covariate file\n",
    "cov_df = upswing_df[['Location']].drop_duplicates()\n",
    "cov_df['cov_1w'] = 1\n",
    "cov_df.to_csv(f'{model_out_dir}/us_cov.csv', index=False)\n",
    "\n",
    "# # run model\n",
    "# if not os.path.exists(f'{model_out_dir}/us'):\n",
    "#     os.mkdir(f'{model_out_dir}/us')\n",
    "# submit_curvefit(102, \n",
    "#                 model_location='United States of America',\n",
    "#                 data_file=f'{model_out_dir}/us_deaths.csv', \n",
    "#                 cov_file=f'{model_out_dir}/us_cov.csv', \n",
    "#                 output_dir=f'{model_out_dir}/us')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model and compile draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read model outputs\n",
    "while not os.path.exists(f'{model_out_dir}/us/death_model.pkl'):\n",
    "    print(f'    Waiting for death model...')\n",
    "    time.sleep(30)\n",
    "with open(f'{model_out_dir}/us/death_model.pkl', 'rb') as fread:\n",
    "    death_model = pickle.load(fread)\n",
    "    \n",
    "# get draws for each location\n",
    "draw_dfs = []\n",
    "\n",
    "for location_id, location in zip(upswing_df['location_id'].unique(), upswing_df['Location'].unique()):\n",
    "    days = death_model.beta['draws'][f'_{location_id}'][0]\n",
    "    days = days - days.min()\n",
    "    draws = np.vstack([death_model.beta['draws'][f'_{location_id}'][1], \n",
    "                       death_model.p['draws'][f'_{location_id}'][1]])\n",
    "    draws = draws[np.argsort(draws[:,-1]),:]\n",
    "    draw_df = pd.DataFrame(np.exp(draws.T) * upswing_df.loc[upswing_df['location_id'] == location_id, 'population'].values[0],\n",
    "                           columns=[f'draw_{i}' for i in range(1000)])\n",
    "    draw_df['date'] = [pd.Timestamp('2020-05-01') + np.timedelta64(d,'D') for d in days]\n",
    "    draw_df = draw_df.loc[draw_df['date'] <= pd.Timestamp('2020-07-15')]\n",
    "    draw_df['location_id'] = location_id\n",
    "    draw_df['location'] = location\n",
    "    draw_df['observed'] = False\n",
    "    draw_dfs.append(draw_df)\n",
    "draw_df = pd.concat(draw_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily(ddf, draw_cols=[f'draw_{i}' for i in range(1000)]):\n",
    "    ddf = ddf.sort_values('date').reset_index(drop=True)\n",
    "    daily = ddf[draw_cols].values[1:,:] - ddf[draw_cols].values[:-1,:]\n",
    "    ddf = ddf.iloc[1:]\n",
    "    ddf[draw_cols] = daily\n",
    "\n",
    "    return ddf.reset_index(drop=True)\n",
    "\n",
    "for location in upswing_df['Location'].unique():\n",
    "    pub_df = get_daily(death_draws_df.loc[death_draws_df['location'] == location])\n",
    "    cf_df = get_daily(draw_df.loc[draw_df['location'] == location])\n",
    "    \n",
    "    cf_df = pub_df.append(cf_df[pub_df.columns]).reset_index(drop=True)\n",
    "    cf_df = cf_df.groupby(['location', 'date'], as_index=False)[[f'draw_{i}' for i in range(1000)]].sum()\n",
    "    \n",
    "    pub_df['daily_mean'] = pub_df[[f'draw_{i}' for i in range(1000)]].mean(axis=1)\n",
    "    pub_df['daily_lower'] = np.percentile(pub_df[[f'draw_{i}' for i in range(1000)]], 2.5, axis=1)\n",
    "    pub_df['daily_upper'] = np.percentile(pub_df[[f'draw_{i}' for i in range(1000)]], 97.5, axis=1)\n",
    "    \n",
    "    cf_df['daily_mean'] = cf_df[[f'draw_{i}' for i in range(1000)]].mean(axis=1)\n",
    "    cf_df['daily_lower'] = np.percentile(cf_df[[f'draw_{i}' for i in range(1000)]], 2.5, axis=1)\n",
    "    cf_df['daily_upper'] = np.percentile(cf_df[[f'draw_{i}' for i in range(1000)]], 97.5, axis=1)\n",
    "\n",
    "    pub_df = get_daily(pub_df)\n",
    "    cf_df = get_daily(cf_df)\n",
    "\n",
    "    plt.figure(figsize=(16.5, 8.5))\n",
    "    plt.fill_between(pub_df['date'],\n",
    "                     pub_df['daily_lower'], pub_df['daily_upper'],\n",
    "                     color='dodgerblue', alpha=0.5)\n",
    "    plt.plot(pub_df['date'],\n",
    "             pub_df['daily_mean'],\n",
    "             color='dodgerblue', label='estimate')\n",
    "    plt.fill_between(cf_df['date'],\n",
    "                     cf_df['daily_lower'], cf_df['daily_upper'],\n",
    "                     color='firebrick', alpha=0.5)\n",
    "    plt.plot(cf_df['date'],\n",
    "             cf_df['daily_mean'],\n",
    "             color='firebrick', label='counterfactual')\n",
    "    plt.legend()\n",
    "    plt.title(location)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
