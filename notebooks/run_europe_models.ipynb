{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from datetime import datetime, timedelta\n",
    "from multiprocessing import Pool\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 99\n",
    "pd.options.display.max_columns = 99\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from covid_model_deaths.data import get_input_data, plot_crude_rates, DeathModelData\n",
    "from covid_model_deaths.social_distancing_cov import SocialDistCov\n",
    "from covid_model_deaths.drawer import Drawer\n",
    "from covid_model_deaths.utilities import CompareModelDeaths, MOBILITY_SOURCES, KS, RATE_THRESHOLD, submit_curvefit, get_peak_date\n",
    "from covid_model_deaths.impute_death_threshold import impute_death_threshold\n",
    "from covid_model_deaths.moving_average import moving_average_predictions\n",
    "from covid_model_deaths.compare_moving_average import CompareAveragingModelDeaths\n",
    "\n",
    "from db_queries import get_location_metadata\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "RUN_TYPE = 'dev'\n",
    "DATESTAMP_LABEL = '2020_04_16_Europe'\n",
    "DATA_VERSION = 'best'\n",
    "PEAK_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_14/final_peak_locs_04_14.csv'\n",
    "CASES_DEATHS_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_14/deaths_from_cases.csv'\n",
    "\n",
    "# ensemble plot settings\n",
    "COLOR_DICT = {\n",
    "    'safegraph':'dodgerblue',\n",
    "    'google':'forestgreen',\n",
    "    'descartes':'firebrick'\n",
    "    #'equal':'gold',\n",
    "    #'ascmid':'firebrick',\n",
    "    #'ascmax':'darkviolet'\n",
    "}\n",
    "LINE_DICT = {\n",
    "    #'14':'-',\n",
    "    '21':'--'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_DIR = os.path.abspath('../src/covid_model_deaths')\n",
    "OUTPUT_DIR = f'/ihme/covid-19/deaths/{RUN_TYPE}/{DATESTAMP_LABEL}'\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "print(f'Writing to {OUTPUT_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# come up with more informative names...\n",
    "input_full_df = get_input_data('full_data', DATA_VERSION)\n",
    "input_death_df = get_input_data('deaths', DATA_VERSION)\n",
    "input_age_pop_df = get_input_data('age_pop', DATA_VERSION)\n",
    "input_age_death_df = get_input_data('age_death', DATA_VERSION)\n",
    "\n",
    "# fix ' names for now\n",
    "input_full_df['Province/State'] = input_full_df['Province/State'].str.replace(\"'\", \"\")\n",
    "input_death_df['Location'] = input_death_df['Location'].str.replace(\"'\", \"\")\n",
    "\n",
    "# manually adjust Iceland spike (0 deaths to 5 deaths to 0 deaths in March...)\n",
    "input_full_df.loc[(input_full_df['Country/Region'] == 'Iceland') & (input_full_df['Date'] == pd.Timestamp('2020-03-15')), ['Deaths', 'Death rate']] = 0\n",
    "input_death_df = input_death_df.loc[(input_death_df['Country/Region'] != 'Iceland') | (input_death_df['Date'] != pd.Timestamp('2020-03-15'))]\n",
    "input_death_df.loc[input_death_df['Country/Region'] == 'Iceland', 'Days'] = input_death_df.loc[\n",
    "    input_death_df['Country/Region'] == 'Iceland', 'Date'\n",
    "].apply(lambda x: (x - input_death_df.loc[input_death_df['Country/Region'] == 'Iceland', 'Date'].min()).days)\n",
    "\n",
    "# drop Georgia the country until we fix location_ids\n",
    "input_full_df = input_full_df[input_full_df['Country/Region'] != 'Georgia'].reset_index(drop=True)\n",
    "input_death_df = input_death_df[input_death_df['Country/Region'] != 'Georgia'].reset_index(drop=True)\n",
    "\n",
    "# # make a picture\n",
    "# plot_crude_rates(input_death_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## identify locations we are running\n",
    "#### European national level outside of Germany, Spain, Italy (the first two being extra-curricular locations)\n",
    "#### change this to use new location sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get locaton_ids\n",
    "loc_df = get_location_metadata(location_set_id=111, location_set_version_id=630)\n",
    "loc_df['location_name'] = loc_df['location_ascii_name']\n",
    "\n",
    "# Drop any locations in the US and keep only most detailed for modeling\n",
    "euro_df = loc_df.loc[\n",
    "    (loc_df['most_detailed']==1) & ~loc_df['path_to_top_parent'].str.startswith('102,'), \n",
    "    ['location_id', 'location_name','parent_id','level']\n",
    "]\n",
    "\n",
    "# format\n",
    "euro_df = euro_df.rename(index=str, columns={'location_name':'Location'})\n",
    "loc_df = loc_df[['location_id', 'location_name']]\n",
    "loc_df = loc_df.rename(index=str, columns={'location_id':'parent_id',\n",
    "                                           'location_name':'Country/Region'})\n",
    "euro_df = euro_df.merge(loc_df)\n",
    "euro_df['Location'] = euro_df['Location'].str.replace(\"'\", \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data for case-to-death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "location_ids = sorted(input_full_df.loc[(np.log(input_full_df['Death rate']) > RATE_THRESHOLD), \n",
    "                                  'location_id'].unique())\n",
    "\n",
    "start_time = datetime.now()\n",
    "def combine_cases_w_backcast_deaths(location_id, input_death_df, input_age_pop_df, input_age_death_df, rate_threshold):\n",
    "    mod_df = DeathModelData(input_death_df, input_age_pop_df, input_age_death_df, location_id, 'threshold', rate_threshold=RATE_THRESHOLD).df\n",
    "    mod_df = mod_df.loc[mod_df['location_id'] == location_id].reset_index(drop=True)\n",
    "    if len(mod_df) > 0:\n",
    "        date0 = mod_df['Date'].min()\n",
    "        day0 = mod_df.loc[~mod_df['Date'].isnull(), 'Days'].min()\n",
    "        mod_df.loc[mod_df['Days'] == 0, 'Date'] = date0 - timedelta(days=np.round(day0))\n",
    "        mod_df = mod_df.loc[~((mod_df['Deaths'].isnull()) & (mod_df['Date'] == date0))]\n",
    "        mod_df = mod_df.loc[~mod_df['Date'].isnull()]\n",
    "        mod_df.loc[mod_df['Death rate'].isnull(), 'Death rate'] = np.exp(mod_df['ln(age-standardized death rate)'])\n",
    "        mod_df.loc[mod_df['Deaths'].isnull(), 'Deaths'] = mod_df['Death rate'] * mod_df['population']\n",
    "        mod_df = mod_df.rename(index=str, columns={'Location':'Province/State'})\n",
    "    else:\n",
    "        mod_df = pd.DataFrame(\n",
    "            columns=['location_id', 'Province/State', 'Country/Region', 'Date', 'Deaths', 'Death rate', 'population']\n",
    "        )\n",
    "\n",
    "    return mod_df[['location_id', 'Province/State', 'Country/Region', 'Date', 'Deaths', 'Death rate', 'population']].reset_index(drop=True)\n",
    "\n",
    "_combiner = functools.partial(combine_cases_w_backcast_deaths, \n",
    "                              input_death_df=input_death_df, \n",
    "                              input_age_pop_df=input_age_pop_df, \n",
    "                              input_age_death_df=input_age_death_df, \n",
    "                              rate_threshold=RATE_THRESHOLD)\n",
    "pool = Pool(20)\n",
    "loc_dfs = pool.map(_combiner, location_ids)\n",
    "pool.close()\n",
    "pool.join()\n",
    "loc_df = pd.concat(loc_dfs)\n",
    "loc_df = input_full_df[['location_id', 'Province/State', 'Country/Region', 'Date', 'Confirmed', 'Confirmed case rate']].merge(\n",
    "    loc_df, how='outer'\n",
    ").reset_index(drop=True)\n",
    "loc_df.loc[loc_df['Province/State'].isnull(), 'Province/State'] = loc_df['Country/Region']\n",
    "loc_df['location_id'] = loc_df['location_id'].astype(int)\n",
    "loc_df.to_csv(f'{OUTPUT_DIR}/backcast_for_case_to_death.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = impute_death_threshold(loc_df,\n",
    "                                 location_list=euro_df['Location'].unique().tolist(),\n",
    "                                 ln_death_rate_threshold=RATE_THRESHOLD)\n",
    "id_map_df = input_full_df[['location_id', 'Province/State', 'Country/Region']].drop_duplicates()\n",
    "id_map_df.loc[id_map_df['Province/State'].isnull(), 'Province/State'] = id_map_df['Country/Region']\n",
    "del id_map_df['Country/Region']\n",
    "id_map_df = id_map_df.rename(index=str, columns={'Province/State':'location'})\n",
    "date_df = id_map_df.merge(date_df)\n",
    "date_df.to_csv(f'{OUTPUT_DIR}/threshold_dates.csv', index=False)\n",
    "del loc_df\n",
    "del id_map_df\n",
    "end_time = datetime.now()\n",
    "print(end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store pops for Bobby\n",
    "pop_df = input_age_pop_df.merge(euro_df).reset_index(drop=True)\n",
    "pop_df[['location_id', 'Location', 'age_group', 'population']].to_csv(f'{OUTPUT_DIR}/pops.csv', index=False)\n",
    "print(f'{OUTPUT_DIR}/pops.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store model data and covariate data, submit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for getting dates\n",
    "def date_mean(dates):\n",
    "    dt_min = dates.min()\n",
    "    deltas = [x-dt_min for x in dates]\n",
    "\n",
    "    return dt_min + functools.reduce(operator.add, deltas) / len(deltas)\n",
    "\n",
    "# get mean data from dataset\n",
    "date_draws = [i for i in date_df.columns if i.startswith('death_date_draw_')]\n",
    "date_mean_df = date_df.copy()\n",
    "date_mean_df['threshold_date'] = date_mean_df.apply(\n",
    "    lambda x: datetime.strptime(date_mean(x[date_draws]).strftime('%Y-%m-%d'), '%Y-%m-%d'),\n",
    "    axis=1\n",
    ")\n",
    "date_mean_df = date_mean_df.rename(index=str, columns={'location':'Location'})\n",
    "country_label_df = input_full_df[['Province/State', 'Country/Region']].drop_duplicates().reset_index(drop=True)\n",
    "country_label_df.loc[country_label_df['Province/State'].isnull(), 'Province/State'] = country_label_df['Country/Region']\n",
    "country_label_df = country_label_df.rename(index=str, columns={'Province/State':'Location'})\n",
    "date_mean_df = date_mean_df.merge(country_label_df, how='outer')\n",
    "if date_mean_df['Country/Region'].isnull().any():\n",
    "    raise ValueError('Trouble attaching country names,')\n",
    "date_mean_df = date_mean_df[['location_id', 'Location', 'Country/Region', 'threshold_date']]\n",
    "\n",
    "# set up ensemble\n",
    "def get_out_dirs(model_labels):\n",
    "    model_out_dirs = []\n",
    "    for model_label in model_labels:\n",
    "        for k in KS:\n",
    "            # set up dirs\n",
    "            model_out_dir = f'{OUTPUT_DIR}/model_data_{model_label}_{k}'\n",
    "            if not os.path.exists(model_out_dir):\n",
    "                os.mkdir(model_out_dir)\n",
    "            model_out_dirs.append(model_out_dir)\n",
    "            \n",
    "    return model_out_dirs\n",
    "def get_draw_list(n_scenarios):\n",
    "    n_draws_list = [int(1000 / n_scenarios)] * n_scenarios\n",
    "    n_draws_list[-1] = n_draws_list[-1] + 1000 - np.sum(n_draws_list)\n",
    "    \n",
    "    return n_draws_list\n",
    "    \n",
    "# prepare last day dataset\n",
    "last_day_df = input_full_df.copy()\n",
    "last_day_df['last_day'] = last_day_df.groupby('location_id', as_index=False)['Date'].transform(max)\n",
    "last_day_df = last_day_df.loc[last_day_df['Date'] == last_day_df['last_day']].reset_index(drop=True)\n",
    "last_day_df['location_id'] = last_day_df['location_id'].astype(int)\n",
    "last_day_df.loc[last_day_df['Death rate'] == 0, 'Death rate'] = 0.1 / last_day_df['population']\n",
    "last_day_df['ln(death rate)'] = np.log(last_day_df['Death rate'])\n",
    "last_day_df = last_day_df[['location_id', 'ln(death rate)', 'Date']].merge(date_mean_df)\n",
    "last_day_df['Days'] = (last_day_df['Date'] - last_day_df['threshold_date'])\n",
    "last_day_df['Days'] = last_day_df['Days'].apply(lambda x: x.days)\n",
    "last_day_df = last_day_df.loc[last_day_df['Days'] > 0]\n",
    "last_day_df[['location_id', 'ln(death rate)', 'Days']].to_csv(f'{OUTPUT_DIR}/last_day.csv', index=False)\n",
    "    \n",
    "# read in data for cases-to-deaths\n",
    "cases_deaths_df = pd.read_csv(CASES_DEATHS_FILE)\n",
    "cases_deaths_df['Date'] = pd.to_datetime(cases_deaths_df['Date'])\n",
    "\n",
    "# run models\n",
    "submodel_dict = {}\n",
    "for location_id, location, country in zip(euro_df['location_id'], euro_df['Location'], euro_df['Country/Region']):\n",
    "    # run model\n",
    "    if location == country:\n",
    "        print(f'Running {location}')\n",
    "        mod_df = DeathModelData(input_death_df, input_age_pop_df, input_age_death_df, location_id, 'threshold', rate_threshold=RATE_THRESHOLD).df\n",
    "    else:\n",
    "        print(f'Running {country} -- {location}')\n",
    "        mod_df = DeathModelData(input_death_df, input_age_pop_df, input_age_death_df, location_id, 'threshold', subnat=True, rate_threshold=RATE_THRESHOLD).df\n",
    "    mod_df = mod_df.loc[~(mod_df['Deaths'].isnull())].reset_index(drop=True)\n",
    "    mod_df = mod_df.loc[~mod_df['Location'].isin(['Life Care Center, Kirkland, WA'])]\n",
    "    \n",
    "    # flag as true data\n",
    "    mod_df['pseudo'] = 0\n",
    "    \n",
    "    # tack on deaths from cases if in dataset\n",
    "    if location_id in input_full_df['location_id'].tolist() and \\\n",
    "        location_id not in [84]:  # Ireland\n",
    "        # get future days\n",
    "        last_date = input_full_df.loc[input_full_df['location_id'] == location_id, 'Date'].max()\n",
    "        loc_cd_df = cases_deaths_df.loc[(cases_deaths_df['location_id'] == location_id) &\n",
    "                                        (cases_deaths_df['Date'] > last_date)].reset_index(drop=True)\n",
    "        loc_cd_df['population'] = input_full_df.loc[input_full_df['location_id'] == location_id, \n",
    "                                                    'population'].max()  # all the same...\n",
    "        loc_cd_df['pseudo'] = 1\n",
    "        \n",
    "        # convert to days\n",
    "        if location_id in mod_df['location_id'].tolist():\n",
    "            last_day = mod_df.loc[mod_df['location_id'] == location_id, 'Days'].max()\n",
    "            loc_cd_df['Days'] = last_day + 1 + loc_cd_df.index\n",
    "        else:\n",
    "            threshold = date_mean_df.loc[date_mean_df['location_id'] == location_id, 'threshold_date'].item()\n",
    "            loc_cd_df['Days'] = loc_cd_df['Date'].apply(lambda x: (x - threshold).days)\n",
    "        loc_cd_df = loc_cd_df.loc[loc_cd_df['Days'] >= 0]\n",
    "            \n",
    "        # stick on to dataset\n",
    "        mod_df = mod_df.append(loc_cd_df)\n",
    "        mod_df = mod_df.sort_values(['location_id', 'Days']).reset_index(drop=True)\n",
    "    \n",
    "    # figure out which models we are running (will need to check about R0=1 model)\n",
    "    submodels = MOBILITY_SOURCES.copy()\n",
    "    submodel_dirs = get_out_dirs(submodels)\n",
    "    \n",
    "    # how many draws for each\n",
    "    n_draws_list = get_draw_list(n_scenarios=len(submodel_dirs))\n",
    "    \n",
    "    # store this information\n",
    "    submodel_dict.update({\n",
    "        int(location_id):{\n",
    "            'submodel_dirs':submodel_dirs,\n",
    "            'n_draws_list':n_draws_list\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    n_i = 0\n",
    "    for cov_source in MOBILITY_SOURCES:\n",
    "        if cov_source in MOBILITY_SOURCES:\n",
    "            covariate_effect = 'gamma'\n",
    "        else:\n",
    "            raise ValueError('Not expecting beta covariate at this time.')\n",
    "            covariate_effect = 'beta'\n",
    "        for k in KS:\n",
    "            # drop back-cast, and submit model\n",
    "            model_out_dir = f'{OUTPUT_DIR}/model_data_{cov_source}_{k}'\n",
    "            mod_df.loc[mod_df['Location'] == \"Valle d'Aosta\", 'Location'] = 'Valle dAosta'  # fix back so it matches the file\n",
    "            mod_df.to_csv(f'{model_out_dir}/{location}.csv', index=False)\n",
    "            mod_df.loc[mod_df['Location'] == 'Valle dAosta', 'Location'] = \"Valle d'Aosta\"  # fix so we get the right merge_name (gotta fully move to ids...)\n",
    "            sd_cov = SocialDistCov(mod_df, date_mean_df, data_version=DATA_VERSION)\n",
    "            if cov_source in MOBILITY_SOURCES:\n",
    "                sd_cov_df = sd_cov.get_cov_df(weights=[None], k=k, empirical_weight_source=cov_source)\n",
    "            else:\n",
    "                raise ValueError('Only expecting mobility weight model at this time.')\n",
    "                sd_cov_df = sd_cov.get_cov_df(weights=weights, k=k)\n",
    "            sd_cov_df.loc[sd_cov_df['Location'] == \"Valle d'Aosta\", 'Location'] = 'Valle dAosta'  # fix back so it matches the file\n",
    "            sd_cov_df.to_csv(f'{model_out_dir}/{location} covariate.csv', index=False)\n",
    "            if not os.path.exists(f'{model_out_dir}/{location}'):\n",
    "                os.mkdir(f'{model_out_dir}/{location}')\n",
    "            submit_curvefit(job_name=f'curve_model_{location_id}_{cov_source}_{k}',\n",
    "                            location_id=location_id, \n",
    "                            code_dir=CODE_DIR,\n",
    "                            model_location=location,\n",
    "                            model_location_id=location_id,\n",
    "                            data_file=f'{model_out_dir}/{location}.csv', \n",
    "                            cov_file=f'{model_out_dir}/{location} covariate.csv', \n",
    "                            last_day_file=f'{OUTPUT_DIR}/last_day.csv',\n",
    "                            peaked_file=PEAK_FILE,\n",
    "                            output_dir=f'{model_out_dir}/{location}',\n",
    "                            covariate_effect=covariate_effect,\n",
    "                            n_draws=n_draws_list[n_i],\n",
    "                            python=shutil.which('python'),\n",
    "                            verbose=True)\n",
    "            n_i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine everything\n",
    "draw_dfs = []\n",
    "past_draw_dfs = []\n",
    "models_used = []\n",
    "with PdfPages(f'{OUTPUT_DIR}/ensemble_plot.pdf') as pdf:\n",
    "    for location_id, location_name in zip(euro_df['location_id'], euro_df['Location']):\n",
    "        print(location_name)\n",
    "        peak_duration = 1\n",
    "        data_draws = Drawer(\n",
    "            ensemble_dirs=submodel_dict[int(location_id)]['submodel_dirs'],\n",
    "            n_draws_list=submodel_dict[int(location_id)]['n_draws_list'],\n",
    "            location_name=location_name, \n",
    "            location_id=int(location_id), \n",
    "            peak_duration=1,\n",
    "            obs_df=input_full_df[input_full_df['location_id'] == int(location_id)],\n",
    "            date_draws=date_df.loc[date_df['location'] == location_name, [i for i in date_df.columns if i.startswith('death_date_draw_')]].values, \n",
    "            population=input_age_pop_df.loc[input_age_pop_df['location_id'] == int(location_id), 'population'].sum(),\n",
    "        )\n",
    "        draw_df, past_draw_df, model_used, days, ensemble_draws = data_draws.get_dated_draws()\n",
    "        draw_dfs.append(draw_df)\n",
    "        past_draw_dfs.append(past_draw_df)\n",
    "        models_used.append(model_used)\n",
    "\n",
    "        # plot ensemble\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(11, 8.5))\n",
    "        for label, draws in ensemble_draws.items():\n",
    "            label = label.split('model_data_')[1]\n",
    "            draws = np.exp(draws) * input_age_pop_df.loc[input_age_pop_df['location_id'] == int(location_id), 'population'].sum()\n",
    "            deaths_mean = draws.mean(axis=0)\n",
    "            deaths_lower = np.percentile(draws, 2.5, axis=0)\n",
    "            deaths_upper = np.percentile(draws, 97.5, axis=0)\n",
    "\n",
    "            d_deaths_mean = (draws[:,1:] - draws[:,:-1]).mean(axis=0)\n",
    "            d_deaths_lower = np.percentile(draws[:,1:] - draws[:,:-1], 2.5, axis=0)\n",
    "            d_deaths_upper = np.percentile(draws[:,1:] - draws[:,:-1], 97.5, axis=0)\n",
    "\n",
    "            # cumulative\n",
    "            ax[0].fill_between(days,\n",
    "                               deaths_lower, deaths_upper,\n",
    "                               color=COLOR_DICT[label.split('_')[0]], \n",
    "                               linestyle=LINE_DICT[label.split('_')[1]], \n",
    "                               alpha=0.25)\n",
    "            ax[0].plot(days, deaths_mean, \n",
    "                       c=COLOR_DICT[label.split('_')[0]], \n",
    "                       linestyle=LINE_DICT[label.split('_')[1]], )\n",
    "            ax[0].set_title(f'constant: {k}')\n",
    "            ax[0].set_xlabel('Date')\n",
    "            ax[0].set_ylabel('Cumulative death rate')\n",
    "\n",
    "            # daily\n",
    "            ax[1].fill_between(days[1:],\n",
    "                               d_deaths_lower, d_deaths_upper,\n",
    "                               color=COLOR_DICT[label.split('_')[0]], \n",
    "                               linestyle=LINE_DICT[label.split('_')[1]], \n",
    "                               alpha=0.25)\n",
    "            ax[1].plot(days[1:], d_deaths_mean, \n",
    "                       c=COLOR_DICT[label.split('_')[0]], \n",
    "                       linestyle=LINE_DICT[label.split('_')[1]], \n",
    "                       label=label.replace('model_data_', ''))\n",
    "            ax[1].set_xlabel('Date')\n",
    "            ax[1].set_ylabel('Daily death rates')\n",
    "\n",
    "        ax[1].legend(loc=2)\n",
    "        plt.suptitle(f'{location_name} ({model_used})')\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "if 'location' not in models_used:\n",
    "    raise ValueError('No location-specific draws used, must be using wrong tag')\n",
    "draw_df = pd.concat(draw_dfs)\n",
    "model_type_df = pd.DataFrame({\n",
    "    'location':euro_df['Location'].to_list(),\n",
    "    'model_used':models_used\n",
    "})\n",
    "\n",
    "# write\n",
    "if 'draw_999' not in draw_df.columns:\n",
    "    draw_df['draw_999'] = draw_df['draw_998']\n",
    "\n",
    "draw_df.loc[draw_df['location'] == 'Valle dAosta', 'location'] = \"Valle d'Aosta\"\n",
    "draw_df.to_csv(f'{OUTPUT_DIR}/euro_data.csv', index=False)\n",
    "model_type_df.to_csv(f'{OUTPUT_DIR}/euro_models_used.csv', index=False)\n",
    "print(f'{OUTPUT_DIR}/euro_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine with previous predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "# raw_draw_path = f'{OUTPUT_DIR}/euro_data.csv'\n",
    "# average_draw_path = f'{OUTPUT_DIR}/past_avg_euro_data.csv'\n",
    "# yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_10_Europe/euro_data.csv'\n",
    "# before_yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_09_Europe/euro_data.csv'\n",
    "# ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "\n",
    "# avg_df = moving_average_predictions(\n",
    "#     'Europe', \n",
    "#     specified=True,\n",
    "#     model_1=raw_draw_path,\n",
    "#     model_2=yesterday_draw_path,\n",
    "#     model_3=before_yesterday_draw_path\n",
    "# )\n",
    "# avg_df['date'] = pd.to_datetime(avg_df['date'])\n",
    "# past_draw_df = pd.concat(past_draw_dfs)\n",
    "\n",
    "# ## NO NEED TO DO THIS, FOR NOW ##\n",
    "# # avg_df = get_peak_date(past_draw_df, avg_df)\n",
    "\n",
    "# # store data\n",
    "# avg_df.to_csv(average_draw_path, index=False)\n",
    "# print(average_draw_path)\n",
    "\n",
    "# # plot\n",
    "# plotter = CompareAveragingModelDeaths(\n",
    "#     raw_draw_path=raw_draw_path,\n",
    "#     average_draw_path=average_draw_path,\n",
    "#     yesterday_draw_path=yesterday_draw_path,\n",
    "#     before_yesterday_draw_path=before_yesterday_draw_path\n",
    "#     )\n",
    "# plotter.make_some_pictures(f'{OUTPUT_DIR}/moving_average_compare.pdf',\n",
    "#                             'EEA + Australia + New Zealand')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = CompareModelDeaths(\n",
    "    old_draw_path='/ihme/covid-19/deaths/prod/2020_04_12_Europe/past_avg_euro_data.csv',\n",
    "    new_draw_path=f'{OUTPUT_DIR}/euro_data.csv'\n",
    ")\n",
    "plotter.make_some_pictures(f'{OUTPUT_DIR}/compare_to_previous.pdf',\n",
    "                           'EEA + others')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_dir = f'/home/j/Project/covid/results/diagnostics/deaths/{DATESTAMP_LABEL}/'\n",
    "if not os.path.exists(viz_dir):\n",
    "    os.mkdir(viz_dir)\n",
    "for viz_fp in ['compare_to_previous.pdf','ensemble_plot.pdf']:  # ,'moving_average_compare.pdf'\n",
    "    shutil.copyfile(src=f\"{OUTPUT_DIR}/{viz_fp}\", dst=f\"{viz_dir}/{viz_fp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(viz_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
