{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to run for US Counties and Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from datetime import datetime, timedelta\n",
    "from multiprocessing import Pool\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 99\n",
    "pd.options.display.max_columns = 99\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from covid_model_deaths.data import get_input_data, plot_crude_rates, DeathModelData\n",
    "from covid_model_deaths.social_distancing_cov import SocialDistCov\n",
    "from covid_model_deaths.drawer import Drawer\n",
    "from covid_model_deaths.utilities import CompareModelDeaths, MOBILITY_SOURCES, KS, RATE_THRESHOLD, submit_curvefit, get_peak_date\n",
    "from covid_model_deaths.impute_death_threshold import impute_death_threshold\n",
    "from covid_model_deaths.moving_average import moving_average_predictions\n",
    "from covid_model_deaths.compare_moving_average import CompareAveragingModelDeaths\n",
    "\n",
    "from db_queries import get_location_metadata\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Set some arguments and settings #\n",
    "RUN_TYPE = 'dev'\n",
    "DATESTAMP_LABEL = '2020_04_22_Counties'\n",
    "DATA_VERSION = 'hospitals-and-counties/best' #'best'\n",
    "\n",
    "#\n",
    "PEAK_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_14/final_peak_locs_04_14.csv'\n",
    "#CASES_DEATHS_FILE expected columns: location_id,Location,Country/Region,Date,ln(age-standardized death rate)\n",
    "CASES_DEATHS_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_20/deaths_from_cases.csv'\n",
    "# PEAK_DURATION_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_14/smooth_peak_duration.csv'\n",
    "# R0_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_14/R0_dates.csv'\n",
    "\n",
    "CODE_DIR = os.path.abspath('../src/covid_model_deaths')\n",
    "OUTPUT_DIR = f'/ihme/covid-19/deaths/{RUN_TYPE}/{DATESTAMP_LABEL}'\n",
    "\n",
    "# Are we combining with previous predictions?\n",
    "combine_predictions = False\n",
    "raw_draw_path = f'{OUTPUT_DIR}/state_data.csv'\n",
    "average_draw_path = f'{OUTPUT_DIR}/past_avg_state_data.csv'\n",
    "yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_19_US/state_data.csv'\n",
    "before_yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_17_US/state_data.csv'\n",
    "\n",
    "# ensemble plot settings\n",
    "COLOR_DICT = {\n",
    "    'safegraph':'dodgerblue',\n",
    "    'google':'forestgreen',\n",
    "    'descartes':'firebrick',\n",
    "    # 'R0_35':'gold',\n",
    "    # 'R0_50':'darkgrey',\n",
    "    # 'R0_65':'darkviolet'\n",
    "}\n",
    "LINE_DICT = {\n",
    "    #'14':'-',\n",
    "    '21':'--'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /ihme/covid-19/deaths/dev/2020_04_22_Counties\n"
     ]
    }
   ],
   "source": [
    "# CODE_DIR = os.path.abspath('../src/covid_model_deaths')\n",
    "# OUTPUT_DIR = f'/ihme/covid-19/deaths/{RUN_TYPE}/{DATESTAMP_LABEL}'\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "print(f'Writing to {OUTPUT_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ihme/code/covid-19/user/ctroeger/covid-model-deaths/src/covid_model_deaths\n"
     ]
    }
   ],
   "source": [
    "print(CODE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read full (unrestricted) set from snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# come up with more informative names...\n",
    "input_full_df = get_input_data('full_data', DATA_VERSION)\n",
    "input_death_df = get_input_data('deaths', DATA_VERSION)\n",
    "# # Dropping recent Montana data due to slow growth resulting in implausible backcast\n",
    "# input_death_df = input_death_df.loc[(input_death_df['Location']!=\"Montana\") | (input_death_df['Date'] < pd.Timestamp(\"2020-04-01\"))]\n",
    "input_age_pop_df = get_input_data('age_pop', DATA_VERSION)\n",
    "input_age_death_df = get_input_data('age_death', DATA_VERSION)\n",
    "\n",
    "# drop Georgia the country until we fix location_ids\n",
    "input_full_df = input_full_df[input_full_df['Country/Region'] != 'Georgia'].reset_index(drop=True)\n",
    "input_death_df = input_death_df[input_death_df['Country/Region'] != 'Georgia'].reset_index(drop=True)\n",
    "\n",
    "# # read in cov input file (predicted date of R0 == 1) to see if we are using these for a given location\n",
    "# cov_df = pd.read_csv(R0_FILE)\n",
    "# r0_locs = cov_df['location_id'].unique().tolist()\n",
    "# del cov_df\n",
    "r0_locs = []\n",
    "\n",
    "# # less conservative peak ranges\n",
    "# peak_dur_df = pd.read_csv(PEAK_DURATION_FILE)\n",
    "# peak_dur_df = peak_dur_df.loc[peak_dur_df['Location'] != 'Colorado']\n",
    "# peak_dur_df['peak start date'] = pd.to_datetime(peak_dur_df['peak start date'])\n",
    "# peak_dur_df['peak end date'] = pd.to_datetime(peak_dur_df['peak end date'])\n",
    "\n",
    "# plot\n",
    "#plot_crude_rates(input_death_df, level='subnat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A fatal error: Florida and New York have no age-curve populations!\n",
    "# Also missing data for many new CA counties\n",
    "# Not sure of an efficient way to do this but here we go\n",
    "fill_pops = pd.read_csv('/ihme/covid-19/model-inputs/best/age_pop.csv')\n",
    "fl_pops = fill_pops[fill_pops['location_id'] == 532]\n",
    "ny_pops = fill_pops[fill_pops['location_id'] == 555]\n",
    "ca_pops = fill_pops[fill_pops['location_id'] == 527]\n",
    "st_pops = fill_pops[fill_pops['location_id'] == 558]\n",
    "input_age_pop_df = input_age_pop_df.append(fl_pops)\n",
    "input_age_pop_df = input_age_pop_df.append(ny_pops)\n",
    "input_age_pop_df = input_age_pop_df.append(ca_pops)\n",
    "input_age_pop_df = input_age_pop_df.append(st_pops)\n",
    "\n",
    "# Remove empty rows for \n",
    "\n",
    "# Now add counties sequentially\n",
    "county_ids = [787, 790, 792, 794, 796, 799]\n",
    "input_age_pop_df = input_age_pop_df[input_age_pop_df['location_id'] != 787]\n",
    "input_age_pop_df = input_age_pop_df[input_age_pop_df['location_id'] != 790]\n",
    "input_age_pop_df = input_age_pop_df[input_age_pop_df['location_id'] != 792]\n",
    "input_age_pop_df = input_age_pop_df[input_age_pop_df['location_id'] != 794]\n",
    "input_age_pop_df = input_age_pop_df[input_age_pop_df['location_id'] != 796]\n",
    "input_age_pop_df = input_age_pop_df[input_age_pop_df['location_id'] != 799]\n",
    "for ids in county_ids:\n",
    "    county_pops = ca_pops\n",
    "    county_pops['location_id'] = ids\n",
    "    input_age_pop_df = input_age_pop_df.append(county_pops)\n",
    "#input_age_pop_df.tail(75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_age_pop_df[input_age_pop_df['age_group']==None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>age_group</th>\n",
       "      <th>population</th>\n",
       "      <th>age_group_weight_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>558</td>\n",
       "      <td>0 - 10</td>\n",
       "      <td>1.356089e+06</td>\n",
       "      <td>0.117120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>558</td>\n",
       "      <td>10 - 20</td>\n",
       "      <td>1.510868e+06</td>\n",
       "      <td>0.130488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>558</td>\n",
       "      <td>20 - 30</td>\n",
       "      <td>1.509295e+06</td>\n",
       "      <td>0.130352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>558</td>\n",
       "      <td>30 - 40</td>\n",
       "      <td>1.427485e+06</td>\n",
       "      <td>0.123287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>558</td>\n",
       "      <td>40 - 50</td>\n",
       "      <td>1.381344e+06</td>\n",
       "      <td>0.119302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>558</td>\n",
       "      <td>50 - 60</td>\n",
       "      <td>1.562235e+06</td>\n",
       "      <td>0.134924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>558</td>\n",
       "      <td>60 - 70</td>\n",
       "      <td>1.467496e+06</td>\n",
       "      <td>0.126742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>558</td>\n",
       "      <td>70 - 80</td>\n",
       "      <td>8.708250e+05</td>\n",
       "      <td>0.075210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>558</td>\n",
       "      <td>80 - 125</td>\n",
       "      <td>4.929524e+05</td>\n",
       "      <td>0.042574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      location_id age_group    population  age_group_weight_value\n",
       "2574          558    0 - 10  1.356089e+06                0.117120\n",
       "2575          558   10 - 20  1.510868e+06                0.130488\n",
       "2576          558   20 - 30  1.509295e+06                0.130352\n",
       "2577          558   30 - 40  1.427485e+06                0.123287\n",
       "2578          558   40 - 50  1.381344e+06                0.119302\n",
       "2579          558   50 - 60  1.562235e+06                0.134924\n",
       "2580          558   60 - 70  1.467496e+06                0.126742\n",
       "2581          558   70 - 80  8.708250e+05                0.075210\n",
       "2582          558  80 - 125  4.929524e+05                0.042574"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_full_df[input_full_df['location_id'] == 60358]\n",
    "input_age_pop_df[input_age_pop_df['location_id'] == 558]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store pops for bobby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_input_data('us_pops').to_csv(f'{OUTPUT_DIR}/pops.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine back-casted death rates with cases for abie (using model dataset, i.e. admin1 and below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "location_ids = sorted(input_full_df.loc[(np.log(input_full_df['Death rate']) > RATE_THRESHOLD) &\n",
    "                                        (~input_full_df['Province/State'].isnull()),\n",
    "                                        'location_id'].unique())\n",
    "\n",
    "start_time = datetime.now()\n",
    "def combine_cases_w_backcast_deaths(location_id, input_death_df, input_age_pop_df, input_age_death_df, rate_threshold):\n",
    "    mod_df = DeathModelData(input_death_df, input_age_pop_df, input_age_death_df, location_id, 'threshold', subnat=True, rate_threshold=RATE_THRESHOLD).df\n",
    "    mod_df = mod_df.loc[mod_df['location_id'] == location_id].reset_index(drop=True)\n",
    "    if len(mod_df) > 0:\n",
    "        date0 = mod_df['Date'].min()\n",
    "        day0 = mod_df.loc[~mod_df['Date'].isnull(), 'Days'].min()\n",
    "        mod_df.loc[mod_df['Days'] == 0, 'Date'] = date0 - timedelta(days=np.round(day0))\n",
    "        mod_df = mod_df.loc[~((mod_df['Deaths'].isnull()) & (mod_df['Date'] == date0))]\n",
    "        mod_df = mod_df.loc[~mod_df['Date'].isnull()]\n",
    "        mod_df.loc[mod_df['Death rate'].isnull(), 'Death rate'] = np.exp(mod_df['ln(age-standardized death rate)'])\n",
    "        mod_df.loc[mod_df['Deaths'].isnull(), 'Deaths'] = mod_df['Death rate'] * mod_df['population']\n",
    "        mod_df = mod_df.rename(index=str, columns={'Location':'Province/State'})\n",
    "    else:\n",
    "        mod_df = pd.DataFrame(\n",
    "            columns=['location_id', 'Province/State', 'Country/Region', 'Date', 'Deaths', 'Death rate', 'population']\n",
    "        )\n",
    "\n",
    "    return mod_df[['location_id', 'Province/State', 'Country/Region', 'Date', 'Deaths', 'Death rate', 'population']].reset_index(drop=True)\n",
    "\n",
    "\n",
    "_combiner = functools.partial(combine_cases_w_backcast_deaths,\n",
    "                              input_death_df=input_death_df,\n",
    "                              input_age_pop_df=input_age_pop_df,\n",
    "                              input_age_death_df=input_age_death_df,\n",
    "                              rate_threshold=RATE_THRESHOLD)\n",
    "pool = Pool(20)\n",
    "loc_dfs = pool.map(_combiner, location_ids)\n",
    "pool.close()\n",
    "pool.join()\n",
    "loc_df = pd.concat(loc_dfs)\n",
    "loc_df = input_full_df[['location_id', 'Province/State', 'Country/Region', 'Date', 'Confirmed', 'Confirmed case rate']].merge(\n",
    "    loc_df, how='outer'\n",
    ").reset_index(drop=True)\n",
    "loc_df.loc[loc_df['Province/State'].isnull(), 'Province/State'] = loc_df['Country/Region']\n",
    "loc_df['location_id'] = loc_df['location_id'].astype(int)\n",
    "loc_df.to_csv(f'{OUTPUT_DIR}/backcast_for_case_to_death.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only using admin1 and below locations\n",
      "Dropping Outside Wuhan City, Hubei\n",
      "Dropping Outside Hubei\n",
      "Standardizing to population of 532\n",
      "Fix backcasting if we change nursing home observations (drop by name).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Date</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Death rate</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>6.477449</td>\n",
       "      <td>3.059023e-07</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.305802e-07</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.250317e-07</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.722574e-07</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.139346e-07</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.139346e-07</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.500633e-07</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.500633e-07</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.086192e-06</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.369546e-06</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.652901e-06</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>2.550190e-06</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>2.644642e-06</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>2.975222e-06</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>4.014188e-06</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>4.108639e-06</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>7.745022e-06</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>8.028376e-06</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>9.209020e-06</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>1.043689e-05</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>1.114527e-05</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>1.336488e-05</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>1.459275e-05</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>1.671791e-05</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>1.841804e-05</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>2.068487e-05</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>461.000000</td>\n",
       "      <td>2.177107e-05</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>2.356564e-05</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>571.000000</td>\n",
       "      <td>2.696590e-05</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>2.814654e-05</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>3.154680e-05</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>532</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>725.000000</td>\n",
       "      <td>3.423866e-05</td>\n",
       "      <td>2.117489e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    location_id Province/State            Country/Region       Date  \\\n",
       "0           532        Florida  United States of America 2020-03-17   \n",
       "1           532        Florida  United States of America 2020-03-18   \n",
       "2           532        Florida  United States of America 2020-03-19   \n",
       "3           532        Florida  United States of America 2020-03-20   \n",
       "4           532        Florida  United States of America 2020-03-21   \n",
       "5           532        Florida  United States of America 2020-03-22   \n",
       "6           532        Florida  United States of America 2020-03-23   \n",
       "7           532        Florida  United States of America 2020-03-24   \n",
       "8           532        Florida  United States of America 2020-03-25   \n",
       "9           532        Florida  United States of America 2020-03-26   \n",
       "10          532        Florida  United States of America 2020-03-27   \n",
       "11          532        Florida  United States of America 2020-03-28   \n",
       "12          532        Florida  United States of America 2020-03-29   \n",
       "13          532        Florida  United States of America 2020-03-30   \n",
       "14          532        Florida  United States of America 2020-03-31   \n",
       "15          532        Florida  United States of America 2020-04-01   \n",
       "16          532        Florida  United States of America 2020-04-02   \n",
       "17          532        Florida  United States of America 2020-04-03   \n",
       "18          532        Florida  United States of America 2020-04-04   \n",
       "19          532        Florida  United States of America 2020-04-05   \n",
       "20          532        Florida  United States of America 2020-04-06   \n",
       "21          532        Florida  United States of America 2020-04-07   \n",
       "22          532        Florida  United States of America 2020-04-08   \n",
       "23          532        Florida  United States of America 2020-04-09   \n",
       "24          532        Florida  United States of America 2020-04-10   \n",
       "25          532        Florida  United States of America 2020-04-11   \n",
       "26          532        Florida  United States of America 2020-04-12   \n",
       "27          532        Florida  United States of America 2020-04-13   \n",
       "28          532        Florida  United States of America 2020-04-14   \n",
       "29          532        Florida  United States of America 2020-04-15   \n",
       "30          532        Florida  United States of America 2020-04-16   \n",
       "31          532        Florida  United States of America 2020-04-17   \n",
       "\n",
       "        Deaths    Death rate    population  \n",
       "0     6.477449  3.059023e-07  2.117489e+07  \n",
       "1     7.000000  3.305802e-07  2.117489e+07  \n",
       "2     9.000000  4.250317e-07  2.117489e+07  \n",
       "3    10.000000  4.722574e-07  2.117489e+07  \n",
       "4    13.000000  6.139346e-07  2.117489e+07  \n",
       "5    13.000000  6.139346e-07  2.117489e+07  \n",
       "6    18.000000  8.500633e-07  2.117489e+07  \n",
       "7    18.000000  8.500633e-07  2.117489e+07  \n",
       "8    23.000000  1.086192e-06  2.117489e+07  \n",
       "9    29.000000  1.369546e-06  2.117489e+07  \n",
       "10   35.000000  1.652901e-06  2.117489e+07  \n",
       "11   54.000000  2.550190e-06  2.117489e+07  \n",
       "12   56.000000  2.644642e-06  2.117489e+07  \n",
       "13   63.000000  2.975222e-06  2.117489e+07  \n",
       "14   85.000000  4.014188e-06  2.117489e+07  \n",
       "15   87.000000  4.108639e-06  2.117489e+07  \n",
       "16  164.000000  7.745022e-06  2.117489e+07  \n",
       "17  170.000000  8.028376e-06  2.117489e+07  \n",
       "18  195.000000  9.209020e-06  2.117489e+07  \n",
       "19  221.000000  1.043689e-05  2.117489e+07  \n",
       "20  236.000000  1.114527e-05  2.117489e+07  \n",
       "21  283.000000  1.336488e-05  2.117489e+07  \n",
       "22  309.000000  1.459275e-05  2.117489e+07  \n",
       "23  354.000000  1.671791e-05  2.117489e+07  \n",
       "24  390.000000  1.841804e-05  2.117489e+07  \n",
       "25  438.000000  2.068487e-05  2.117489e+07  \n",
       "26  461.000000  2.177107e-05  2.117489e+07  \n",
       "27  499.000000  2.356564e-05  2.117489e+07  \n",
       "28  571.000000  2.696590e-05  2.117489e+07  \n",
       "29  596.000000  2.814654e-05  2.117489e+07  \n",
       "30  668.000000  3.154680e-05  2.117489e+07  \n",
       "31  725.000000  3.423866e-05  2.117489e+07  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # # Single location\n",
    "# # olist = [60387,60381,60405,60384,60387,60416,60408]\n",
    "# # # for l in olist[1]:\n",
    "# t = combine_cases_w_backcast_deaths(532, input_death_df=input_death_df,\n",
    "#                               input_age_pop_df=input_age_pop_df,\n",
    "#                               input_age_death_df=input_age_death_df,\n",
    "#                               rate_threshold=RATE_THRESHOLD)\n",
    "# t\n",
    "# #location_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only using admin1 and below locations\n",
      "Dropping Outside Wuhan City, Hubei\n",
      "Dropping Outside Hubei\n",
      "Only using admin1 and below locations\n",
      "Only using admin1 and below locations\n",
      "Only using admin1 and below locations\n",
      "Dropping Outside Wuhan City, Hubei\n",
      "Dropping Outside Wuhan City, Hubei\n",
      "Only using admin1 and below locations\n",
      "Dropping Outside Hubei\n",
      "Dropping Outside Hubei\n",
      "Dropping Outside Wuhan City, Hubei\n",
      "Dropping Outside Hubei\n",
      "Dropping Outside Wuhan City, Hubei\n",
      "Dropping Outside Hubei\n",
      "Standardizing to population of 536\n",
      "Standardizing to population of 534\n",
      "Standardizing to population of 535\n",
      "Standardizing to population of 533\n",
      "Standardizing to population of 532\n",
      "Fix backcasting if we change nursing home observations (drop by name).\n",
      "Fix backcasting if we change nursing home observations (drop by name).\n",
      "Fix backcasting if we change nursing home observations (drop by name).\n",
      "Fix backcasting if we change nursing home observations (drop by name).\n",
      "Fix backcasting if we change nursing home observations (drop by name).\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:02:33.531025\n"
     ]
    }
   ],
   "source": [
    "date_df = impute_death_threshold(loc_df,\n",
    "                                 location_list=loc_df.loc[(loc_df['Country/Region'] == 'United States of America') &\n",
    "                                                          (~loc_df['Province/State'].isnull()), 'location_id'].unique().tolist(),\n",
    "                                 ln_death_rate_threshold=RATE_THRESHOLD)\n",
    "loc_df = loc_df[['location_id', 'Province/State']].drop_duplicates()\n",
    "loc_df = loc_df.rename(index=str, columns={'Province/State':'location'})\n",
    "date_df = loc_df.merge(date_df)\n",
    "date_df.to_csv(f'{OUTPUT_DIR}/threshold_dates.csv', index=False)\n",
    "del loc_df\n",
    "end_time = datetime.now()\n",
    "print(end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create datasets for each subnational unit of US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get location information\n",
    "loc_df = get_location_metadata(location_set_id=35, gbd_round_id=6)\n",
    "location_ids = loc_df.loc[(loc_df['parent_id'] == 102) & (loc_df['location_name'] != 'Washington'),\n",
    "                          'location_id'].to_list()\n",
    "location_names = loc_df.loc[(loc_df['parent_id'] == 102) & (loc_df['location_name'] != 'Washington'),\n",
    "                           'location_name'].to_list()\n",
    "for wa_location in ['Other Counties, WA',\n",
    "                    'King and Snohomish Counties (excluding Life Care Center), WA',\n",
    "                    'Life Care Center, Kirkland, WA']:\n",
    "    location_ids += [input_full_df.loc[input_full_df['Province/State'] == wa_location, 'location_id'].astype(int).unique().item()]\n",
    "    location_names += [wa_location]\n",
    "\n",
    "## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "## NEED TO ADD OPTION TO ADD NEW YORK + MIAMI (UNTIL WE MOVE TO LOCATION HIERARCHY)\n",
    "## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "\n",
    "# method for getting dates\n",
    "def date_mean(dates):\n",
    "    dt_min = dates.min()\n",
    "    deltas = [x-dt_min for x in dates]\n",
    "\n",
    "    return dt_min + functools.reduce(operator.add, deltas) / len(deltas)\n",
    "\n",
    "# get mean data from dataset\n",
    "date_draws = [i for i in date_df.columns if i.startswith('death_date_draw_')]\n",
    "date_mean_df = date_df.copy()\n",
    "date_mean_df['threshold_date'] = date_mean_df.apply(\n",
    "    lambda x: datetime.strptime(date_mean(x[date_draws]).strftime('%Y-%m-%d'), '%Y-%m-%d'),\n",
    "    axis=1\n",
    ")\n",
    "date_mean_df['Country/Region'] = 'United States of America'\n",
    "date_mean_df = date_mean_df.rename(index=str, columns={'location':'Location'})\n",
    "date_mean_df = date_mean_df[['location_id', 'Location', 'Country/Region', 'threshold_date']]\n",
    "\n",
    "# set up ensemble\n",
    "def get_out_dirs(model_labels):\n",
    "    model_out_dirs = []\n",
    "    for model_label in model_labels:\n",
    "        for k in KS:\n",
    "            # set up dirs\n",
    "            model_out_dir = f'{OUTPUT_DIR}/model_data_{model_label}_{k}'\n",
    "            if not os.path.exists(model_out_dir):\n",
    "                os.mkdir(model_out_dir)\n",
    "            model_out_dirs.append(model_out_dir)\n",
    "\n",
    "    return model_out_dirs\n",
    "def get_draw_list(n_scenarios):\n",
    "    n_draws_list = [int(1000 / n_scenarios)] * n_scenarios\n",
    "    n_draws_list[-1] = n_draws_list[-1] + 1000 - np.sum(n_draws_list)\n",
    "\n",
    "    return n_draws_list\n",
    "\n",
    "# prepare last day dataset\n",
    "last_day_df = input_full_df.copy()\n",
    "last_day_df['last_day'] = last_day_df.groupby('location_id', as_index=False)['Date'].transform(max)\n",
    "last_day_df = last_day_df.loc[last_day_df['Date'] == last_day_df['last_day']].reset_index(drop=True)\n",
    "last_day_df['location_id'] = last_day_df['location_id'].astype(int)\n",
    "last_day_df.loc[last_day_df['Death rate'] == 0, 'Death rate'] = 0.1 / last_day_df['population']\n",
    "last_day_df['ln(death rate)'] = np.log(last_day_df['Death rate'])\n",
    "last_day_df = last_day_df[['location_id', 'ln(death rate)', 'Date']].merge(date_mean_df)\n",
    "last_day_df['Days'] = (last_day_df['Date'] - last_day_df['threshold_date'])\n",
    "last_day_df['Days'] = last_day_df['Days'].apply(lambda x: x.days)\n",
    "last_day_df = last_day_df.loc[last_day_df['Days'] > 0]\n",
    "last_day_df[['location_id', 'ln(death rate)', 'Days']].to_csv(f'{OUTPUT_DIR}/last_day.csv', index=False)\n",
    "\n",
    "# read in data for cases-to-deaths\n",
    "cases_deaths_df = pd.read_csv(CASES_DEATHS_FILE)\n",
    "cases_deaths_df['Date'] = pd.to_datetime(cases_deaths_df['Date'])\n",
    "\n",
    "# submit models\n",
    "submodel_dict = {}\n",
    "N = len(location_ids)\n",
    "i = 0\n",
    "nursing_home_locations = ['Life Care Center, Kirkland, WA']\n",
    "for location_id, location_name in zip(location_ids, location_names):\n",
    "    i += 1\n",
    "    print(f'{i} / {N} locations')\n",
    "    mod = DeathModelData(input_death_df, input_age_pop_df, input_age_death_df, location_id, 'threshold', subnat=True, rate_threshold=RATE_THRESHOLD)\n",
    "    if location_name in nursing_home_locations:\n",
    "        # save only nursing homes\n",
    "        mod_df = mod.df.copy()\n",
    "    else:\n",
    "        # save only others\n",
    "        mod_df = mod.df.loc[~mod.df['Location'].isin(nursing_home_locations)].reset_index(drop=True)\n",
    "    # drop back-cast\n",
    "    mod_df = mod_df.loc[~(mod_df['Deaths'].isnull())].reset_index(drop=True)\n",
    "\n",
    "    # flag as true data\n",
    "    mod_df['pseudo'] = 0\n",
    "\n",
    "    # tack on deaths from cases if in dataset\n",
    "    if location_id in input_full_df['location_id'].tolist() and \\\n",
    "        location_id not in [564, 538]:  # South Dakota, Iowa\n",
    "        # get future days\n",
    "        last_date = input_full_df.loc[input_full_df['location_id'] == location_id, 'Date'].max()\n",
    "        loc_cd_df = cases_deaths_df.loc[(cases_deaths_df['location_id'] == location_id) &\n",
    "                                        (cases_deaths_df['Date'] > last_date)].reset_index(drop=True)\n",
    "\n",
    "        loc_cd_df['population'] = input_full_df.loc[input_full_df['location_id'] == location_id,\n",
    "                                                    'population'].max()  # all the same...\n",
    "        loc_cd_df['pseudo'] = 1\n",
    "\n",
    "        # convert to days\n",
    "        if location_id in mod_df['location_id'].tolist():\n",
    "            last_day = mod_df.loc[mod_df['location_id'] == location_id, 'Days'].max()\n",
    "            loc_cd_df['Days'] = last_day + 1 + loc_cd_df.index\n",
    "        else:\n",
    "            threshold = date_mean_df.loc[date_mean_df['location_id'] == location_id, 'threshold_date'].item()\n",
    "            loc_cd_df['Days'] = loc_cd_df['Date'].apply(lambda x: (x - threshold).days)\n",
    "        loc_cd_df = loc_cd_df.loc[loc_cd_df['Days'] >= 0]\n",
    "\n",
    "        # stick on to dataset\n",
    "        mod_df = mod_df.append(loc_cd_df)\n",
    "        mod_df = mod_df.sort_values(['location_id', 'Days']).reset_index(drop=True)\n",
    "\n",
    "    # figure out which models we are running (will need to check about R0=1 model)\n",
    "    submodels = MOBILITY_SOURCES.copy()\n",
    "    if location_id in r0_locs:\n",
    "        submodels += ['R0_35', 'R0_50', 'R0_65']\n",
    "    submodel_dirs = get_out_dirs(submodels)\n",
    "\n",
    "    # how many draws for each\n",
    "    n_draws_list = get_draw_list(n_scenarios=len(submodel_dirs))\n",
    "\n",
    "    # store this information\n",
    "    submodel_dict.update({\n",
    "        int(location_id):{\n",
    "            'submodel_dirs':submodel_dirs,\n",
    "            'n_draws_list':n_draws_list\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # run models\n",
    "    n_i = 0\n",
    "    for cov_source in submodels:\n",
    "        if cov_source in MOBILITY_SOURCES:\n",
    "            covariate_effect = 'gamma'\n",
    "        else:\n",
    "            covariate_effect = 'beta'\n",
    "        for k in KS:\n",
    "            # drop back-cast for modeling file, but NOT for the social distancing covariate step\n",
    "            model_out_dir = f'{OUTPUT_DIR}/model_data_{cov_source}_{k}'\n",
    "            mod_df.to_csv(f'{model_out_dir}/{location_id}.csv', index=False)\n",
    "            sd_cov = SocialDistCov(mod_df, date_mean_df, data_version=DATA_VERSION)\n",
    "            if cov_source in MOBILITY_SOURCES:\n",
    "                sd_cov_df = sd_cov.get_cov_df(weights=[None], k=k, empirical_weight_source=cov_source)\n",
    "            else:\n",
    "                sd_cov_df = sd_cov.get_cov_df(weights=[None], k=k, empirical_weight_source=cov_source, R0_file=R0_FILE)\n",
    "            sd_cov_df.to_csv(f'{model_out_dir}/{location_id}_covariate.csv', index=False)\n",
    "            if not os.path.exists(f'{model_out_dir}/{location_id}'):\n",
    "                os.mkdir(f'{model_out_dir}/{location_id}')\n",
    "            submit_curvefit(job_name=f'curve_model_{location_id}_{cov_source}_{k}',\n",
    "                            location_id=location_id,\n",
    "                            code_dir=CODE_DIR,\n",
    "                            model_location_id=location_id,\n",
    "                            data_file=f'{model_out_dir}/{location_id}.csv',\n",
    "                            cov_file=f'{model_out_dir}/{location_id}_covariate.csv',\n",
    "                            last_day_file=f'{OUTPUT_DIR}/last_day.csv',\n",
    "                            peaked_file=PEAK_FILE,\n",
    "                            output_dir=f'{model_out_dir}/{location_id}',\n",
    "                            covariate_effect=covariate_effect,\n",
    "                            n_draws=n_draws_list[n_i],\n",
    "                            python=shutil.which('python'),\n",
    "                            verbose=False)\n",
    "            n_i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset US\n",
    "usa_obs_df = input_full_df[(input_full_df['Country/Region'] == 'United States of America') &\n",
    "                           (~input_full_df['Province/State'].isnull())]\n",
    "\n",
    "# combine everything\n",
    "draw_dfs = []\n",
    "past_draw_dfs = []\n",
    "models_used = []\n",
    "with PdfPages(f'{OUTPUT_DIR}/ensemble_plot.pdf') as pdf:\n",
    "    for location_id, location_name in zip(location_ids, location_names):\n",
    "        # # identify peak duration\n",
    "        # if int(location_id) in peak_dur_df['location_id'].to_list():\n",
    "        #     print(f'{location_name}: observed peak')\n",
    "        #     peak_duration = peak_dur_df.loc[peak_dur_df['location_id'] == int(location_id), 'peak durations'].item()\n",
    "        # else:\n",
    "        #     print(f'{location_name}: average peak')\n",
    "        #     peak_duration = 5\n",
    "        # peak_duration = int(np.round(peak_duration))\n",
    "        # print(f'Peak length: {peak_duration}')\n",
    "        peak_duration = 1\n",
    "        # get draws\n",
    "        data_draws = Drawer(\n",
    "            ensemble_dirs=submodel_dict[int(location_id)]['submodel_dirs'],\n",
    "            n_draws_list=submodel_dict[int(location_id)]['n_draws_list'],\n",
    "            location_name=location_name,\n",
    "            location_id=int(location_id),\n",
    "            peak_duration=peak_duration,\n",
    "            obs_df=usa_obs_df.loc[usa_obs_df['location_id'] == int(location_id)],\n",
    "            date_draws=date_df.loc[date_df['location'] == location_name, date_draws].values,\n",
    "            population=input_age_pop_df.loc[input_age_pop_df['location_id'] == int(location_id), 'population'].sum()\n",
    "        )\n",
    "        draw_df, past_draw_df, model_used, days, ensemble_draws = data_draws.get_dated_draws()\n",
    "        draw_dfs.append(draw_df)\n",
    "        past_draw_dfs.append(past_draw_df)\n",
    "        models_used.append(model_used)\n",
    "\n",
    "        # plot ensemble\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(11, 8.5))\n",
    "        for label, draws in ensemble_draws.items():\n",
    "            label = label.split('model_data_')[1]\n",
    "            draws = np.exp(draws) * input_age_pop_df.loc[input_age_pop_df['location_id'] == int(location_id), 'population'].sum()\n",
    "            deaths_mean = draws.mean(axis=0)\n",
    "            deaths_lower = np.percentile(draws, 2.5, axis=0)\n",
    "            deaths_upper = np.percentile(draws, 97.5, axis=0)\n",
    "\n",
    "            d_deaths_mean = (draws[:,1:] - draws[:,:-1]).mean(axis=0)\n",
    "            d_deaths_lower = np.percentile(draws[:,1:] - draws[:,:-1], 2.5, axis=0)\n",
    "            d_deaths_upper = np.percentile(draws[:,1:] - draws[:,:-1], 97.5, axis=0)\n",
    "\n",
    "            # cumulative\n",
    "            ax[0].fill_between(days,\n",
    "                               deaths_lower, deaths_upper,\n",
    "                               color=COLOR_DICT['_'.join(label.split('_')[:-1])],\n",
    "                               linestyle=LINE_DICT[label.split('_')[-1]],\n",
    "                               alpha=0.25)\n",
    "            ax[0].plot(days, deaths_mean,\n",
    "                       c=COLOR_DICT['_'.join(label.split('_')[:-1])],\n",
    "                       linestyle=LINE_DICT[label.split('_')[-1]])\n",
    "            ax[0].set_xlabel('Date')\n",
    "            ax[0].set_ylabel('Cumulative death rate')\n",
    "\n",
    "            # daily\n",
    "            ax[1].fill_between(days[1:],\n",
    "                               d_deaths_lower, d_deaths_upper,\n",
    "                               color=COLOR_DICT['_'.join(label.split('_')[:-1])],\n",
    "                               linestyle=LINE_DICT[label.split('_')[-1]],\n",
    "                               alpha=0.25)\n",
    "            ax[1].plot(days[1:], d_deaths_mean,\n",
    "                       c=COLOR_DICT['_'.join(label.split('_')[:-1])],\n",
    "                       linestyle=LINE_DICT[label.split('_')[-1]],\n",
    "                       label=label.replace('model_data_', ''))\n",
    "            ax[1].set_xlabel('Date')\n",
    "            ax[1].set_ylabel('Daily death rates')\n",
    "\n",
    "        ax[1].legend(loc=2)\n",
    "        plt.suptitle(f'{location_name} ({model_used})')\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "if 'location' not in models_used:\n",
    "    raise ValueError('No location-specific draws used, must be using wrong tag')\n",
    "draw_df = pd.concat(draw_dfs)\n",
    "model_type_df = pd.DataFrame({\n",
    "    'location':location_names,\n",
    "    'model_used':models_used\n",
    "})\n",
    "\n",
    "# write\n",
    "draw_df.to_csv(f'{OUTPUT_DIR}/state_data.csv', index=False)\n",
    "model_type_df.to_csv(f'{OUTPUT_DIR}/state_models_used.csv', index=False)\n",
    "print(f'{OUTPUT_DIR}/state_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total US deaths in this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_cols = [f'draw_{i}' for i in range(1000)]\n",
    "nat_df = draw_df.groupby('date', as_index=False)[draw_cols].sum()\n",
    "nat_df = nat_df.loc[nat_df['date'] == pd.Timestamp('2020-07-15')]\n",
    "deaths_mean = int(nat_df[draw_cols].mean(axis=1).item())\n",
    "deaths_lower = int(np.percentile(nat_df[draw_cols], 2.5, axis=1).item())\n",
    "deaths_upper = int(np.percentile(nat_df[draw_cols], 97.5, axis=1).item())\n",
    "f'{deaths_mean:,} ({deaths_lower:,} - {deaths_upper:,})'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine with previous predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "# Moved to the top cell.\n",
    "# raw_draw_path = f'{OUTPUT_DIR}/state_data.csv'\n",
    "# average_draw_path = f'{OUTPUT_DIR}/past_avg_state_data.csv'\n",
    "# yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_17_US/state_data.csv'\n",
    "# before_yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_16_US/state_data.csv'\n",
    "## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "\n",
    "if combine_predictions:\n",
    "    avg_df = moving_average_predictions(\n",
    "        today_data_path=raw_draw_path,\n",
    "        yesterday_data_path=yesterday_draw_path,\n",
    "        day_before_yesterday_path=before_yesterday_draw_path\n",
    "    )\n",
    "    avg_df['date'] = pd.to_datetime(avg_df['date'])\n",
    "    past_draw_df = pd.concat(past_draw_dfs)\n",
    "\n",
    "    ## NO NEED TO DO THIS, FOR NOW ##\n",
    "    # avg_df = get_peak_date(past_draw_df, avg_df)\n",
    "\n",
    "    # store data\n",
    "    avg_df.to_csv(average_draw_path, index=False)\n",
    "    print(average_draw_path)\n",
    "\n",
    "    # plot\n",
    "    plotter = CompareAveragingModelDeaths(\n",
    "        raw_draw_path=raw_draw_path,\n",
    "        average_draw_path=average_draw_path,\n",
    "        yesterday_draw_path=yesterday_draw_path,\n",
    "        before_yesterday_draw_path=before_yesterday_draw_path\n",
    "        )\n",
    "    plotter.make_some_pictures(f'{OUTPUT_DIR}/moving_average_compare.pdf',\n",
    "                               'United States of America')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = CompareModelDeaths(\n",
    "    old_draw_path='/ihme/covid-19/deaths/prod/2020_04_16_US/state_data.csv',\n",
    "    new_draw_path=f'{OUTPUT_DIR}/past_avg_state_data.csv'\n",
    ")\n",
    "plotter.make_some_pictures(f'{OUTPUT_DIR}/compare_to_previous.pdf',\n",
    "                           'United States of America')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viz_dir = f'/home/j/Project/covid/results/diagnostics/deaths/{DATESTAMP_LABEL}/'\n",
    "if not os.path.exists(viz_dir):\n",
    "    os.mkdir(viz_dir)\n",
    "for viz_fp in ['compare_to_previous.pdf','ensemble_plot.pdf','moving_average_compare.pdf']:\n",
    "    shutil.copyfile(src=f\"{OUTPUT_DIR}/{viz_fp}\", dst=f\"{viz_dir}/{viz_fp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(viz_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
